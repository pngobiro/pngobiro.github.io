

  212
1. Each outcome in a markov process belongs to a state space or transition
matrix. E.g.
             S1      S2 S3
        S1  P11 P12 P13 
                                    Where S1, S2, S3 are states and P11 P12 e.t.c are
        S2  P21 P22 P23 
        S3  P31 P32 P33 
        probabilities

2. The outcome of each trial depends on the immediate preceding activities
    but not on the previous activities

BASIC TERMS IN MARKOV CHAINS
   a) Probability Vector




                                                                        om
   This is a row matrix whose elements are non-negative and also they add




                                                                    i.c
   up to 1 e.g. u = 0.2, 0.1, 0.2, 0.5)
   Example
                                                                ng
                                                            si
   Consider u = (¾, 0, - ¼, 1/2) Not because – ¼ is negative
                                                      om

                  v = (¾, ½, 0, ¼)             Not because the sum of the element <1
                  w= (¼, ¼, 0, ½)              Adds up to 1, each element is non
                                               om



   negative.
                                        as




                                               Therefore it‘s a prob, vector
                                      .m
                             w




State the ones which are probability vectors
                             w




   b) Stochastic matrix
                         w




   A matrix whose row elements are all non negative and also add up to 1.
                                        0.1   0.2    0.3   0.4 
                                                               
                                         0.0   0.7    0.1   0.2 
        Example (i) M                 =
                                        0.5   0.1    0.1   0.3 
                                                               
                                        0.3   0.4    0.2   0.1 
        Example ii) = Consider the following matrices
                   13   0    2
                                                                   0 1 0
                                               1      
                              3
                  3                                                         
                                                      3
        A=        4
                         1
                         2      1
                                  4        B =  14   4
                                                      1
                                                                C =  12 16 13 
                  1     1    1               3     3             1 2 0
                  3     3    3                                    3 3       

  213
A is not stochastic matrix because the element in the 2 nd row and 3rd
column is negative.
B is not stochastic matrix because the elements in the second row do not
add up to 1
C is stochastic matrix because each element is non negative and they add
up to 1 in each row.

   c) Regular stochastic matrix
   A matrix P is said to be regular stochastic matrix if all the elements in
