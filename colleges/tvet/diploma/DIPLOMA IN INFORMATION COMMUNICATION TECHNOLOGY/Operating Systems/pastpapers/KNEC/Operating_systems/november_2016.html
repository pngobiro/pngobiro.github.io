<!doctype html>
<html lang="en">
<head>
<link rel="stylesheet" type="text/css" href="base.css" />
<link rel="stylesheet" type="text/css" href="content.css" />
<link rel="stylesheet" type="text/css" href="nav.css" />
<meta http-equiv="content-type" content="text/html;  charset=utf-8" />
<title>November 2016 </title>
<link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<meta name="generator" content="eXeLearning 2.9 - exelearning.net" />
<!--[if lt IE 9]><script type="text/javascript" src="exe_html5.js"></script><![endif]-->
<script type="text/javascript" src="exe_jquery.js"></script>
<script type="text/javascript" src="common_i18n.js"></script>
<script type="text/javascript" src="common.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
</head>
<body class="exe-web-site" id="exe-node-8"><script type="text/javascript">document.body.className+=" js"</script>
<div id="content">
<p id="skipNav"><a href="#main" class="sr-av">Skip navigation</a></p>
<section id="emptyHeader"></section>
<nav id="siteNav">
<ul>
   <li><a href="index.html" class="daddy main-node">Home</a></li>
   <li><a href="july_2023.html" class="no-ch">July 2023</a></li>
   <li><a href="november_2021.html" class="no-ch">November 2021</a></li>
   <li><a href="july_2021.html" class="no-ch">July 2021</a></li>
   <li><a href="july_2019.html" class="no-ch">July 2019</a></li>
   <li><a href="november_2018.html" class="no-ch">November 2018</a></li>
   <li><a href="november_2017.html" class="no-ch">November 2017</a></li>
   <li><a href="july_2017.html" class="no-ch">July 2017</a></li>
   <li id="active"><a href="november_2016.html" class="active no-ch">November 2016</a></li>
   <li><a href="july_2016.html" class="no-ch">July 2016</a></li>
   <li><a href="november_2015.html" class="no-ch">November 2015</a></li>
   <li><a href="july_2015.html" class="no-ch">July 2015</a></li>
   <li><a href="novemeber_2014.html" class="no-ch">Novemeber 2014</a></li>
   <li><a href="july_2014.html" class="no-ch">July 2014</a></li>
   <li><a href="november_2013.html" class="no-ch">November 2013</a></li>
   <li><a href="july_2013.html" class="no-ch">July 2013</a></li>
   <li><a href="november_2012.html" class="no-ch">November 2012</a></li>
   <li><a href="july_2012.html" class="no-ch">July 2012</a></li>
   <li><a href="july_2011.html" class="no-ch">July 2011</a></li>
</ul>
</nav>
<div id='topPagination'>
<nav class="pagination noprt">
<a href="july_2017.html" class="prev"><span><span>&laquo; </span>Previous</span></a> <span class="sep">| </span><a href="july_2016.html" class="next"><span>Next<span> &raquo;</span></span></a>
</nav>
</div>
<div id="main-wrapper">
<section id="main">
<header id="nodeDecoration"><h1 id="nodeTitle">November 2016</h1></header>
<article class="iDevice_wrapper textIdevice" id="id8">
<div class="iDevice emphasis0" >
<div id="ta8_130_2" class="block iDevice_content">
<div class="exe-text"><p></p>
<style>
        /* Modern CSS Reset */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        /* Base Styles */
        body {
            font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;
            line-height: 1.6;
            color: #2d3748;
            background-color: #f7fafc;
            margin: 0;
            padding: 0;
        }

        /* Header Styles */
        header {
            background: linear-gradient(135deg, #1a365d 0%, #2c5282 100%);
            color: white;
            padding: 2rem;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        header h1 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
            font-weight: 600;
        }

        .exam-details {
            background: rgba(255, 255, 255, 0.1);
            padding: 1rem;
            border-radius: 8px;
            display: inline-block;
            margin-top: 1rem;
        }

        .exam-details p {
            margin: 0.5rem 0;
            font-size: 1.1rem;
        }

        /* Main Content */
        main {
            max-width: 1200px;
            margin: 2rem auto;
            padding: 0 1.5rem;
        }

        /* Passage Styles */
        .passage {
            background: #edf2f7;
            border-radius: 12px;
            margin-bottom: 2rem;
            padding: 1.5rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
        }

        .passage h2 {
            color: #2d3748;
            margin-bottom: 1rem;
            font-size: 1.5rem;
            border-bottom: 2px solid #cbd5e0;
            padding-bottom: 0.5rem;
        }

        .passage-content {
            font-size: 1.1rem;
            color: #4a5568;
            line-height: 1.8;
        }

        .passage-content p {
            margin-bottom: 1rem;
        }

        /* Question Styles */
        .question {
            background: white;
            border-radius: 12px;
            margin-bottom: 2rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
            overflow: hidden;
        }

        .question h3 {
            background: #4a5568;
            color: white;
            padding: 1rem 1.5rem;
            font-size: 1.25rem;
            margin: 0;
            border-bottom: 3px solid #2d3748;
        }

        .question-content {
            padding: 1.5rem;
            background: #fff;
            border-bottom: 2px solid #edf2f7;
        }

        .question-content p {
            font-size: 1.1rem;
            color: #2d3748;
        }

        /* Answer Styles */
        .answer-section {
            background: #f8fafc;
            border-top: 2px solid #e2e8f0;
        }

        .answer-section h4 {
            padding: 1rem 1.5rem;
            color: #2d3748;
            font-size: 1.2rem;
            background: #edf2f7;
            margin: 0;
        }

        .answer-content {
            padding: 1.5rem;
            color: #4a5568;
        }

        .answer-content p {
            margin-bottom: 1rem;
            line-height: 1.8;
        }

        /* Bold Answers */
        .answer-content strong, .answer-content b {
            color: #2d3748;
            font-weight: 700;
        }

        /* Numbered Lists in Answers */
        .answer-content p[data-number]:before {
            content: attr(data-number) ".";
            font-weight: 600;
            margin-right: 0.5rem;
            color: #4a5568;
        }

        /* Table Styles */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
            overflow: hidden;
            border-radius: 8px;
        }

        thead {
            background-color: #4a5568;
            color: white;
        }

        th {
            text-align: left;
            padding: 0.75rem 1rem;
            font-weight: 600;
            border-bottom: 2px solid #2d3748;
        }

        td {
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            background-color: white;
        }

        tr:last-child td {
            border-bottom: none;
        }

        tr:nth-child(even) td {
            background-color: #f8fafc;
        }

        /* Footer Styles */
        footer {
            background: #2d3748;
            color: white;
            text-align: center;
            padding: 1.5rem;
            margin-top: 3rem;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            header h1 {
                font-size: 2rem;
            }

            main {
                padding: 0 1rem;
            }

            .passage h2 {
                font-size: 1.3rem;
            }

            .passage-content p {
                font-size: 1rem;
            }

            .question {
                margin-bottom: 1.5rem;
            }

            .question h3 {
                font-size: 1.1rem;
            }

            .question-content p,
            .answer-content p {
                font-size: 1rem;
            }
            
            table, thead, tbody, th, td, tr {
                display: block;
            }
            
            thead tr {
                position: absolute;
                top: -9999px;
                left: -9999px;
            }
            
            tr {
                border: 1px solid #e2e8f0;
                margin-bottom: 1rem;
                border-radius: 8px;
                overflow: hidden;
            }
            
            td {
                border: none;
                position: relative;
                padding-left: 50%;
                text-align: left;
                border-bottom: 1px solid #e2e8f0;
            }
            
            td:before {
                position: absolute;
                top: 0.75rem;
                left: 1rem;
                width: 45%;
                padding-right: 10px;
                white-space: nowrap;
                font-weight: 600;
                content: attr(data-label);
            }
            
            td:last-child {
                border-bottom: 0;
            }
        }

        /* Print Styles */
        @media print {
            body {
                background: white;
            }

            .passage,
            .question {
                break-inside: avoid;
                box-shadow: none;
                border: 1px solid #edf2f7;
            }

            header {
                background: white;
                color: black;
                padding: 1rem;
            }

            .exam-details {
                border: 1px solid #edf2f7;
            }
            
            table {
                break-inside: auto;
            }
            
            tr {
                break-inside: avoid;
                break-after: auto;
            }
        }
    </style>
<header>
<h1>OPERATING SYSTEMS</h1>
<div class="exam-details">
<p>Exam Code: 2920/105</p>
<p>Duration: 3 hours</p>
<p>Period: November 2016</p>
</div>
</header>
<p></p>
<p></p>
<p><main>
<section class="question">
<h3>1. (a) (2 marks)</h3>
<div class="question-content">
<p>(a) Explain the term system call as applied in operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>A <strong>system call</strong> is a <strong>request made by a user-level process to the operating system kernel</strong> to perform a privileged operation. It acts as the <strong>interface between user space and kernel space</strong>, allowing user programs to request services from the OS, such as I/O operations, process creation, and memory allocation.</p>
</div>
</div>
</section>
<section class="question">
<h3>1. (b) (4 marks)</h3>
<div class="question-content">
<p>(b) Outline four benefits of virtual memory in computers.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Running Larger Programs</strong>: Virtual memory allows users to run <strong>programs larger than the physical RAM</strong> available. It achieves this by using disk space as an extension of RAM, swapping portions of programs (pages) between disk and memory as needed.</p>
<p data-number="2"><strong>Increased Multiprogramming</strong>: By enabling programs larger than physical memory to run, virtual memory <strong>increases the degree of multiprogramming</strong>. More processes can reside in memory (partially), improving CPU utilization and system throughput.</p>
<p data-number="3"><strong>Efficient Memory Utilization</strong>: Virtual memory leads to more <strong>efficient utilization of physical RAM</strong>. Only the necessary parts of a program are loaded into memory, freeing up space for other processes or data.</p>
<p data-number="4"><strong>Memory Protection</strong>: Virtual memory enhances <strong>memory protection</strong>. Each process operates in its own virtual address space, isolated from other processes, preventing unauthorized access and interference.</p>
</div>
</div>
</section>
<section class="question">
<h3>1. (c) (6 marks)</h3>
<div class="question-content">
<p>(c) Describe three strategies that could be used to mitigate deadlocks in operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Deadlock Prevention</strong>: <strong>Deadlock prevention</strong> aims to <strong>prevent deadlocks by ensuring that at least one of the necessary conditions for deadlock cannot hold</strong>. These conditions are mutual exclusion, hold and wait, no preemption, and circular wait. Prevention techniques might include: * <strong>Mutual Exclusion</strong>: Not easily preventable, as some resources are inherently non-sharable. * <strong>Hold and Wait</strong>: Processes must request all required resources before execution or release all held resources before requesting new ones. * <strong>No Preemption</strong>: If a process holding certain resources requests another resource that cannot be immediately allocated, the held resources are preempted (temporarily taken away). * <strong>Circular Wait</strong>: Impose a linear ordering of resource types and require that each process requests resources in an increasing order of enumeration.</p>
<p data-number="2"><strong>Deadlock Avoidance</strong>: <strong>Deadlock avoidance</strong> allows all four deadlock conditions to be possible but makes <strong>dynamic decisions about resource allocation to ensure that the system never enters a deadlock state</strong>. This often involves using algorithms like the Banker's Algorithm. Avoidance requires the system to have prior information about the maximum resource needs of each process. The system then analyzes each resource request to ensure that granting it will keep the system in a 'safe state' (a state from which all processes can complete without deadlock).</p>
<p data-number="3"><strong>Deadlock Detection and Recovery</strong>: <strong>Deadlock detection and recovery</strong> allow deadlocks to occur, then <strong>detect and resolve them</strong>. Detection involves periodically checking the system state to see if a deadlock has occurred, typically by building and searching a resource allocation graph for cycles. Once a deadlock is detected, recovery strategies may include: * <strong>Process Termination</strong>: Aborting one or more processes involved in the deadlock. This can be drastic, potentially losing progress. Selection of processes to abort can be based on priority, progress made, or resources held. * <strong>Resource Preemption</strong>: Forcibly taking resources away from one or more deadlocked processes. This is only feasible if the resource state can be easily saved and restored. The preempted process may need to be rolled back to a safe state and restarted.</p>
</div>
</div>
</section>
<section class="question">
<h3>1. (d) (4 marks)</h3>
<div class="question-content">
<p>(d) (i) Several resources are prerequisite for a successful process execution by the CPU. Outline four examples of these resources that should be availed to the CPU.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>CPU Time</strong>: <strong>CPU time</strong> is the fundamental resource required for process execution. The CPU needs to allocate processing cycles to the process so it can execute its instructions. Scheduling algorithms determine how CPU time is distributed among competing processes.</p>
<p data-number="2"><strong>Memory</strong>: <strong>Memory (RAM)</strong> is essential for storing the process's code, data, and stack. The CPU fetches instructions and data from memory to execute the process. Sufficient memory must be allocated to the process for it to run effectively.</p>
<p data-number="3"><strong>Input/Output (I/O) Devices</strong>: Processes often require access to <strong>I/O devices</strong> such as disks, network interfaces, keyboards, and displays. Access to these devices allows processes to interact with the external environment, read input, and produce output.</p>
<p data-number="4"><strong>Files</strong>: Processes frequently need to access <strong>files</strong> for reading data or storing results. File system resources, including file handles, disk space, and file metadata, are necessary for file operations.</p>
</div>
</div>
</section>
<section class="question">
<h3>1. (d) (4 marks)</h3>
<div class="question-content">
<p>(ii) Sifa was required to identify advantages of the pre-emptive job scheduling techniques. Explain two advantages that she could have identified.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Improved Responsiveness</strong>: <strong>Pre-emptive scheduling</strong> significantly improves system responsiveness, especially for interactive and time-sensitive applications. By allowing the operating system to interrupt (preempt) a running process and switch to another ready process, pre-emptive scheduling ensures that high-priority or interactive tasks can get quick CPU access. This reduces latency and provides a more interactive user experience, as the system remains responsive even under heavy load.</p>
<p data-number="2"><strong>Fairer Allocation of CPU Time</strong>: Pre-emptive scheduling promotes a <strong>fairer allocation of CPU time</strong> among processes. It prevents a single process from monopolizing the CPU for extended periods, which can happen in non-preemptive systems where a long-running process can block shorter or higher-priority processes. Techniques like time-slicing in Round Robin scheduling, a pre-emptive algorithm, ensure that each process gets a fair share of CPU time over time, improving overall system fairness and preventing starvation of processes.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (a) (3 marks)</h3>
<div class="question-content">
<p>(a) Outline three file operations that could be applied to a file.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Create</strong>: The <strong>create</strong> operation is used to <strong>establish a new file</strong> in the file system. It involves allocating storage space for the file and creating a directory entry with the file's name and attributes. Creating a file makes it ready for data to be written into it.</p>
<p data-number="2"><strong>Read</strong>: The <strong>read</strong> operation allows for <strong>retrieving data from an existing file</strong>. It involves accessing the file's contents from the storage medium and transferring the data to memory for processing or display. Reading a file is a fundamental operation for accessing and using stored information.</p>
<p data-number="3"><strong>Write</strong>: The <strong>write</strong> operation is used to <strong>store data into a file</strong>. It involves transferring data from memory to the file on the storage medium, updating the file's contents. Writing to a file is essential for saving new information or modifying existing file data.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (b) (i) (2 marks)</h3>
<div class="question-content">
<p>(b) (1) Define the term sector as applied in computer storage.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>A <strong>sector</strong> in computer storage, particularly in hard disk drives and floppy disks, is the <strong>smallest physical storage unit on a disk</strong>. It is a <strong>fixed-size block of data</strong>, traditionally 512 bytes or 4KB, that can be read or written in a single operation. Sectors are arranged in tracks and are the fundamental unit of data organization and access on disk media.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (b) (ii) (5 marks)</h3>
<div class="question-content">
<p>(ii) With the aid of a diagram, describe file allocation table as used in operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(ii) File Allocation Table (FAT)</strong>:</p>
<p>A <strong>File Allocation Table (FAT)</strong> is a <strong>data structure used by some operating systems to manage file storage on disk</strong>, particularly in older systems like DOS and early Windows versions. It acts as an <strong>index</strong> that maps files to the clusters (groups of sectors) they occupy on the disk. The FAT is essentially a table that resides at the beginning of a disk partition, containing entries for each cluster on the disk. Each entry indicates whether a cluster is free, allocated to a file, or marked as bad. For allocated clusters, it points to the next cluster in the file, forming a chain of clusters for each file.</p>
<p><strong>Diagram of FAT Structure:</strong></p>
<pre>Disk Partition:
+-----------------------+-----------------------+-----------------------+-----+-----------------------+
| Reserved Area         | FAT 1                 | FAT 2 (Backup)        | ... | Data Area             |
+-----------------------+-----------------------+-----------------------+-----+-----------------------+

File Allocation Table (FAT):
+---------+---------+---------+-----+---------+
| Cluster 0| Cluster 1| Cluster 2| ... | Cluster N|
+---------+---------+---------+-----+---------+
| Entry 0 | Entry 1 | Entry 2 | ... | Entry N |  &lt;-- Entries contain cluster status or pointer to next cluster
+---------+---------+---------+-----+---------+

Example FAT Entries:
- 0x0000: Free cluster
- 0xFFFF: End of file cluster chain
- Cluster number: Pointer to the next cluster in the file chain

Directory Entry:
+---------------+---------------+-----+---------------+
| File Name     | Starting      | ... | File Attributes|
|               | Cluster Number|     |                |
+---------------+---------------+-----+---------------+
</pre>
<p><strong>Description:</strong></p>
<p data-number="1"><strong>FAT Location</strong>: The FAT is typically located at the <strong>beginning of a disk partition</strong>, often with a backup copy (FAT2) for redundancy.</p>
<p data-number="2"><strong>Cluster Mapping</strong>: The FAT is an array where each entry corresponds to a <strong>cluster on the disk</strong>. The entry for each cluster indicates its status (free, allocated, bad) or, if allocated, the <strong>number of the next cluster in the file's chain</strong>.</p>
<p data-number="3"><strong>File Allocation</strong>: When a file is created or expanded, the operating system searches the FAT for <strong>free clusters</strong>, allocates them to the file, and updates the FAT entries to link these clusters together in a chain. The directory entry for a file stores the <strong>starting cluster number</strong> of the file.</p>
<p data-number="4"><strong>File Access</strong>: To access a file, the OS reads the starting cluster number from the directory entry and then <strong>traverses the chain of clusters</strong> by following the pointers in the FAT entries until it reaches the end-of-file marker. This linked list structure allows for non-contiguous file allocation.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (c) (i) (2 marks)</h3>
<div class="question-content">
<p>(c) (i) Outline two limitations of fixed memory partitioning.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Internal Fragmentation</strong>: <strong>Internal fragmentation</strong> occurs when a process is allocated a partition larger than its actual memory requirement. The unused space within the partition is wasted and cannot be used by other processes. Since partitions are fixed in size, there is often a mismatch between process size and partition size, leading to inefficient memory utilization.</p>
<p data-number="2"><strong>Limited Multiprogramming Degree</strong>: <strong>Fixed partitioning limits the degree of multiprogramming</strong>. The number of partitions is fixed at system startup, restricting the number of processes that can reside in memory simultaneously. If all partitions are occupied, new processes must wait even if there is enough total free memory, just not in appropriately sized partitions. This can reduce overall system throughput and responsiveness.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (c) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Differentiate between single and double buffering as used in I/O ports registers.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Single Buffering</strong>:</p>
<p>In <strong>single buffering</strong>, a <strong>single buffer</strong> is used in memory for data transfer between an I/O device and the processor via I/O port registers. Data is transferred in chunks, and the processor must wait for each chunk transfer to complete before initiating the next operation. This leads to <strong>alternating periods of data transfer and processing</strong>, with the processor often idle during data transfer. Single buffering is simple but can be inefficient due to the wait times.</p>
<p><strong>Double Buffering</strong>:</p>
<p>In <strong>double buffering</strong>, <strong>two buffers</strong> are used. While one buffer is being filled or emptied by the I/O device (via I/O port registers), the processor can simultaneously process data in the other buffer. This allows for <strong>overlapping of I/O operations with processing</strong>. The processor does not have to wait for each I/O operation to complete before starting processing, reducing idle time and improving throughput. Double buffering enhances efficiency by enabling concurrency between data transfer and processing.</p>
<p><strong>Key Difference:</strong> Single buffering uses one buffer and involves sequential I/O and processing, leading to processor idle time. Double buffering uses two buffers to overlap I/O and processing, reducing idle time and improving efficiency.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (d) (4 marks)</h3>
<div class="question-content">
<p>(d) Tom would like to design a memory system that uses best-fit placement algorithm. Explain two limitations of this algorithm that would affect the performance of the memory.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Increased Search Time for Allocation</strong>: The <strong>best-fit algorithm</strong> requires <strong>searching the entire list of free memory partitions</strong> to find the smallest partition that is large enough to satisfy the memory request. This exhaustive search can be <strong>time-consuming</strong>, especially when there are many free partitions. The overhead of searching for the best fit can increase memory allocation time, impacting system performance, particularly for frequent memory allocation requests.</p>
<p data-number="2"><strong>External Fragmentation</strong>: While best-fit aims to minimize wasted space, it can still lead to <strong>external fragmentation</strong>. By allocating memory from the smallest suitable partition, it tends to leave behind <strong>many small, unusable fragments</strong> of free memory between allocated blocks. Over time, this can result in a situation where there is sufficient total free memory, but it is scattered in small chunks, making it difficult to allocate memory for larger processes that require contiguous blocks. This fragmentation reduces the usability of total memory and can degrade performance.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (a) (i) (2 marks)</h3>
<div class="question-content">
<p>3. (e) Explain each of the following terms as used in operating systems:</p>
<p>(1) kernel;</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Kernel</strong>:</p>
<p>The <strong>kernel</strong> is the <strong>core of an operating system</strong>. It is the <strong>lowest-level software</strong> that has direct control over the system hardware. The kernel provides essential services such as process management, memory management, file system management, device control, and system calls. It acts as a bridge between hardware and user-level applications and is responsible for managing system resources.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (a) (ii) (2 marks)</h3>
<div class="question-content">
<p>(!!) monitor.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(ii) Monitor</strong>:</p>
<p>In operating systems, a <strong>monitor</strong> is a <strong>synchronization construct</strong> used for controlling access to shared resources in concurrent programming. A monitor encapsulates shared data and a set of procedures (methods) that operate on that data. Monitors ensure <strong>mutual exclusion</strong> (only one process can be active inside the monitor at any time) and provide <strong>condition variables</strong> for processes to wait and signal each other within the monitor.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (b) (i) (2 marks)</h3>
<div class="question-content">
<p>(b) Elsie was required to select an operating system that would be used on a server computer to provide a wide range of services to other desktop computers.</p>
<p>(i) Identify the most appropriate type of operating system that she could select justifying your answer.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Network Operating System (NOS)</strong>:</p>
<p>The most appropriate type of operating system Elsie could select is a <strong>Network Operating System (NOS)</strong>. A NOS is specifically designed to <strong>manage server operations and provide network services</strong> to client computers. It is optimized for resource sharing, network management, security, and handling multiple client requests efficiently, making it ideal for server environments providing services to desktop computers.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (b) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Explain two benefits that her company could realize when using the operating system identified in (i).</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Centralized Resource Management and Sharing</strong>: Using a NOS on a server enables <strong>centralized management and sharing of resources</strong>. The server can host and manage resources like files, printers, applications, databases, and internet access, making them available to multiple desktop computers (clients) across the network. This centralized approach simplifies administration, reduces redundancy, and improves resource utilization. It allows for efficient sharing of expensive resources and easier control over access and usage.</p>
<p data-number="2"><strong>Enhanced Security and Control</strong>: A NOS provides <strong>enhanced security and control</strong> over network resources and data. Security features like user authentication, access control lists, firewalls, and encryption can be centrally implemented and managed on the server. This central security administration simplifies the enforcement of security policies, protects sensitive data, and reduces vulnerabilities across the network. A NOS allows for better control over user access, data integrity, and network traffic, improving overall system security posture.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (c) (i) (2 marks)</h3>
<div class="question-content">
<p>(c) (i) Explain the term Remote Procedure Call (RPC) as used in operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Remote Procedure Call (RPC)</strong>:</p>
<p><strong>Remote Procedure Call (RPC)</strong> is a <strong>protocol that allows a program on one computer to execute a procedure or function on another computer over a network</strong> as if it were a local procedure call. RPC abstracts the complexities of network communication, making distributed computing easier. It enables client-server interactions where a client can request services from a server by invoking procedures remotely, simplifying distributed application development.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (c) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Differentiate between communication and storage I/O devices.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Communication I/O Devices</strong>:</p>
<p><strong>Communication I/O devices</strong> are used for <strong>data transfer between computer systems or networks</strong>. They facilitate data exchange over communication channels. Examples include <strong>network interface cards (NICs)</strong>, modems, and serial ports. The primary function of communication I/O devices is to enable networking and data transmission between computers, allowing for distributed processing, network access, and remote communication.</p>
<p><strong>Storage I/O Devices</strong>:</p>
<p><strong>Storage I/O devices</strong> are used for <strong>persistent data storage and retrieval within a computer system</strong>. They provide non-volatile storage for data that needs to be retained even when the system is powered off. Examples include <strong>hard disk drives (HDDs)</strong>, solid-state drives (SSDs), and USB drives. The main purpose of storage I/O devices is to store files, applications, and operating system data, enabling long-term data retention and access.</p>
<p><strong>Key Difference:</strong> Communication I/O devices are for inter-system data exchange over networks, while storage I/O devices are for persistent data storage within a single computer system.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (d) (4 marks)</h3>
<div class="question-content">
<p>(d) A computer is made up of different types of internal buses to facilitate communication. Explain two types of such buses found in a computer system.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Data Bus</strong>: The <strong>data bus</strong> is a set of parallel wires (lines) used to <strong>transfer actual data between components of a computer system</strong>. It carries the binary data being processed or stored. The width of the data bus (number of lines) determines the amount of data that can be transferred simultaneously in one clock cycle. Common data bus widths are 32-bit, 64-bit, or wider. A wider data bus allows for faster data transfer rates, improving system performance.</p>
<p data-number="2"><strong>Address Bus</strong>: The <strong>address bus</strong> is another set of parallel wires used to <strong>specify the memory location or I/O port address that the CPU wants to access</strong>. The CPU places an address on the address bus to select a specific memory location or I/O device for read or write operations. The width of the address bus determines the total amount of memory that the CPU can address. For example, a 32-bit address bus can address 2^32 bytes (4GB) of memory.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (a) (i) (3 marks)</h3>
<div class="question-content">
<p>4. (a) (1) Outline three examples of roles that could be provided by a parent processor.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Process Creation</strong>: A parent processor (or process) is responsible for <strong>creating child processes</strong>. It initiates the execution of new processes, allocating necessary resources and setting up the execution environment for the child processes. Process creation is a fundamental role in process management, allowing for multitasking and parallel processing.</p>
<p data-number="2"><strong>Resource Allocation</strong>: Parent processors can <strong>allocate resources to their child processes</strong>. This includes memory allocation, file access permissions, and access to I/O devices. Resource allocation ensures that child processes have the necessary resources to execute effectively and prevents resource conflicts between processes.</p>
<p data-number="3"><strong>Process Control and Monitoring</strong>: Parent processors play a role in <strong>controlling and monitoring their child processes</strong>. They can manage the execution of child processes, including starting, suspending, resuming, and terminating them. Parent processes can also monitor the status and resource usage of their children, enabling process management and system monitoring functionalities.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (a) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) With the aid of a diagram, describe the burst DMA mode of operations.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(ii) Burst DMA Mode of Operation</strong>:</p>
<p>In <strong>Burst DMA (Direct Memory Access) mode</strong>, the DMA controller <strong>transfers a continuous block of data in a single burst</strong>. Once the DMA controller gains control of the system bus, it transfers multiple data words or bytes in rapid succession without releasing the bus between each transfer. This mode is highly efficient for large data transfers as it minimizes the overhead of bus arbitration for each data unit. The CPU is suspended from bus access during the entire burst transfer.</p>
<p><strong>Diagram of Burst DMA Mode:</strong></p>
<pre>+---------+     +----------+     +----------+     +---------+
|  Device | ----&gt; | DMA      | ----&gt; | Memory   | &lt;----| CPU   |
+---------+     | Controller|     +----------+      Suspend
      Request      +----------+         Data Burst Transfer
          ^             | Bus Grant (One Time)
          |             V
          +----------+
          |   CPU    |
          +----------+
            Initialize DMA, Request Burst Transfer, Wait for Completion
</pre>
<p><strong>Description:</strong></p>
<p data-number="1"><strong>DMA Request and Bus Grant</strong>: The I/O device requests a DMA transfer. The DMA controller requests control of the system bus from the CPU. Once the CPU grants the bus, the DMA controller gains exclusive control for a burst transfer.</p>
<p data-number="2"><strong>Burst Data Transfer</strong>: The DMA controller transfers a <strong>block of data (burst) continuously</strong> between the I/O device and memory <strong>without releasing the bus</strong> after each data unit. It performs multiple read or write operations in quick succession, using the granted bus access efficiently.</p>
<p data-number="3"><strong>CPU Suspension</strong>: During the burst transfer, the <strong>CPU is suspended from accessing the system bus</strong>. It has to wait until the DMA controller completes the entire burst transfer and releases the bus. This is known as cycle stealing, although in burst mode, it's a block of cycles.</p>
<p data-number="4"><strong>Transfer Completion and Bus Release</strong>: After the burst transfer is complete (specified number of bytes transferred), the DMA controller <strong>releases control of the system bus</strong>, and the CPU can resume its bus operations. The DMA controller then notifies the CPU of transfer completion via an interrupt.</p>
<p><strong>Advantage:</strong> Burst DMA mode is very <strong>efficient for high-speed data transfers</strong> because it reduces bus arbitration overhead, leading to higher throughput compared to single-transfer DMA modes.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (b) (5 marks)</h3>
<div class="question-content">
<p>(b) With the aid of a diagram, describe a hierarchical file system.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Hierarchical File System (Tree-Structured Directory)</strong>:</p>
<p>A <strong>hierarchical file system</strong>, also known as a tree-structured directory, is a file organization system that uses a <strong>directory hierarchy</strong> to organize files and directories. It is structured like an inverted tree, with a single root directory at the top, and directories and files branching out from it. This structure allows users to organize files into logical groups and sub-groups, making file management more organized and scalable.</p>
<p><strong>Diagram of Hierarchical File System:</strong></p>
<pre>                      Root Directory (/)
                         |
             +-----------+-----------+
             |                       |
          Directory A             Directory B
             |                       |
     +-------+-------+         +-------+-------+
     |               |         |               |
  Directory C     File 1      Directory D     File 2
     |                         |
 +-----+-----+               +-----+-----+
 |           |               |           |
File 3      File 4         File 5      File 6

... and so on, forming a tree-like structure.
</pre>
<p><strong>Description:</strong></p>
<p data-number="1"><strong>Root Directory</strong>: At the top of the hierarchy is the <strong>root directory</strong>, denoted as '/' in Unix-like systems or drive letter (e.g., 'C:\') in Windows. It is the starting point of the entire file system.</p>
<p data-number="2"><strong>Directories (Folders)</strong>: Directories, also known as folders, are containers that can hold files and other directories (subdirectories). They are used to organize files into logical groupings. Directories create levels in the hierarchy.</p>
<p data-number="3"><strong>Files</strong>: Files are the actual data containers, stored within directories. Each file has a name and resides in a specific directory. Files are the leaf nodes in the tree structure.</p>
<p data-number="4"><strong>Pathnames</strong>: Files and directories are accessed using <strong>pathnames</strong>, which specify the sequence of directories to traverse from the root to reach the target file or directory. Pathnames can be absolute (starting from the root) or relative (starting from the current working directory).</p>
<p data-number="5"><strong>Navigation</strong>: Users can navigate through the directory hierarchy to access files and directories. Operations like creating, deleting, moving, and renaming files and directories are performed within this hierarchical structure.</p>
<p><strong>Advantages:</strong> Hierarchical file systems provide <strong>better organization</strong>, <strong>scalability</strong>, and <strong>manageability</strong> compared to flat file systems. They allow users to structure their data logically, avoid naming conflicts, and efficiently manage large numbers of files.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (c) (4 marks)</h3>
<div class="question-content">
<p>(c) Mark proposed a file encryption technique for his company's file system. Explain two techniques that he could have proposed.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Symmetric Encryption</strong>: Mark could propose using <strong>symmetric encryption</strong> techniques. In symmetric encryption, the <strong>same key is used for both encryption and decryption</strong>. Techniques like AES (Advanced Encryption Standard), DES (Data Encryption Standard), or Triple DES could be employed. When a file is encrypted, it is transformed into an unreadable format using the symmetric key. To decrypt the file and access the original data, the same key must be used. Symmetric encryption is generally faster and more efficient for encrypting large files, making it suitable for file system encryption. Key management and secure key distribution are crucial considerations with symmetric encryption.</p>
<p data-number="2"><strong>Asymmetric Encryption (Public-Key Encryption)</strong>: Mark could also consider <strong>asymmetric encryption</strong>, also known as public-key encryption. Asymmetric encryption uses <strong>key pairs: a public key for encryption and a private key for decryption</strong>. Techniques like RSA (Rivest-Shamir-Adleman) or ECC (Elliptic Curve Cryptography) could be used. Files can be encrypted using the public key, and only the corresponding private key can decrypt them. Asymmetric encryption provides more secure key management as the private key does not need to be shared. It can be used for encrypting files or for secure key exchange to then use symmetric encryption for bulk data encryption. Asymmetric encryption is generally slower than symmetric encryption and is often used in combination with symmetric methods.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (d) (4 marks)</h3>
<div class="question-content">
<p>(d) Deadlocks are inevitable in operating systems. Explain two conditions that should hold to trigger this anomaly.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Mutual Exclusion</strong>: <strong>Mutual exclusion</strong> is a condition where <strong>at least one resource must be held in a non-sharable mode</strong>. This means that only one process at a time can use the resource. If another process requests that resource, it must wait until the resource is released. If mutual exclusion does not hold for all resources, deadlocks cannot occur, as processes could share resources freely.</p>
<p data-number="2"><strong>Hold and Wait</strong>: The <strong>hold and wait</strong> condition occurs when a process is <strong>holding at least one resource and is waiting to acquire additional resources</strong> that are currently being held by other processes. For a deadlock to occur, processes must hold resources while simultaneously requesting new ones. If processes were required to request all needed resources at the start and not hold resources while waiting for others, deadlocks could be prevented.</p>
</div>
</div>
</section>
<section class="question">
<h3>5. (a) (i) (2 marks)</h3>
<div class="question-content">
<p>5. (a) (i) Name two ways of creating processes during execution by operating system.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Forking (System Call)</strong>: The <strong>fork system call</strong> is a common method for process creation. When a process calls fork, the operating system <strong>creates a duplicate of the calling process</strong>. The new process, called the child process, is nearly identical to the parent process, inheriting its code, data, and resources, but with a new process ID (PID).</p>
<p data-number="2"><strong>Exec (System Call)</strong>: The <strong>exec system call</strong> is used to <strong>replace the current process's memory space with a new program</strong>. Typically used after a fork, exec loads and runs a new executable file in the child process's context. This allows a process to initiate and run a completely different program than itself.</p>
</div>
</div>
</section>
<section class="question">
<h3>5. (a) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Outline four advantages of peer-to-peer file sharing.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Decentralization</strong>: <strong>Peer-to-peer (P2P) file sharing</strong> is <strong>decentralized</strong>, meaning there is no central server or authority controlling the file sharing process. This decentralization makes the network more robust and resistant to single points of failure. If one peer goes offline, the network can continue to function as long as other peers are available.</p>
<p data-number="2"><strong>Scalability</strong>: P2P networks are inherently <strong>scalable</strong>. As the number of users (peers) increases, the network's capacity and bandwidth also increase because each new peer contributes resources (bandwidth, storage) to the network. This scalability makes P2P suitable for large user bases and heavy file sharing loads.</p>
<p data-number="3"><strong>Cost-Effective</strong>: P2P file sharing can be <strong>cost-effective</strong> compared to centralized systems. There is no need for expensive central servers and infrastructure. Resources are distributed among peers, reducing infrastructure costs and reliance on central providers.</p>
<p data-number="4"><strong>Increased Availability and Redundancy</strong>: Files shared on P2P networks are often <strong>distributed across multiple peers</strong>. This redundancy enhances file availability. If one peer hosting a file goes offline, other peers may still have copies of the file, ensuring that the file remains accessible to the network. This improves data resilience and availability.</p>
</div>
</div>
</section>
<section class="question">
<h3>5. (b) (4 marks)</h3>
<div class="question-content">
<p>(b) Differentiate between seek time and rotational delay as used in disk management.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Seek Time</strong>:</p>
<p><strong>Seek time</strong> is the <strong>time it takes for the disk arm and read/write head to move to the correct track (cylinder) on the disk surface</strong> where the desired data is located. Seek time is a major component of disk access time and is influenced by the distance the head needs to travel across the disk. Shorter seek times result in faster data access. Disk scheduling algorithms aim to minimize average seek time by optimizing the order in which disk requests are serviced.</p>
<p><strong>Rotational Delay (Latency)</strong>:</p>
<p><strong>Rotational delay</strong>, also known as rotational latency, is the <strong>time it takes for the desired sector of the disk to rotate under the read/write head once the head is positioned over the correct track</strong>. After the seek operation positions the head over the correct track, rotational delay is the time for the disk to spin until the beginning of the requested sector reaches the head. Rotational delay is dependent on the disk's rotation speed (RPM). Higher RPM disks have lower rotational latency.</p>
<p><strong>Key Difference:</strong> Seek time is the time for head movement across tracks, while rotational delay is the time for disk rotation to position the sector under the head after the head is on the correct track. Both contribute to total disk access time.</p>
</div>
</div>
</section>
<section class="question">
<h3>5. (c) (4 marks)</h3>
<div class="question-content">
<p>(c) Identify the type of memory used in each case:</p>
<p>(i) temporarily store results of processing by CPU;</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Registers</strong></p>
</div>
</div>
</section>
<section class="question">
<h3>5. (c) (4 marks)</h3>
<div class="question-content">
<p>(ii) retains stored information event after computer restarts;</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(ii) Secondary Storage (e.g., Hard Disk Drive, SSD)</strong></p>
</div>
</div>
</section>
<section class="question">
<h3>5. (c) (4 marks)</h3>
<div class="question-content">
<p>(iii) portion of hard disk that is logically addressed as a main memory;</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(iii) Virtual Memory (Swap Space/Page File)</strong></p>
</div>
</div>
</section>
<section class="question">
<h3>5. (c) (4 marks)</h3>
<div class="question-content">
<p>(iv) bridges the speed gap between the processor and RAM;</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(iv) Cache Memory</strong></p>
</div>
</div>
</section>
<section class="question">
<h3>5. (d) (6 marks)</h3>
<div class="question-content">
<p>(d) Sam was required to enumerate objectives of inter process communication in operating systems during a regional symposium for programmer's. Explain three objectives that he could have outlined.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Data Sharing</strong>: One primary objective of inter-process communication (IPC) is to enable <strong>data sharing between processes</strong>. IPC mechanisms allow processes to exchange information and data, facilitating collaborative tasks. Processes may need to share data to coordinate activities, process data in stages, or access shared resources. Data sharing through IPC is essential for building complex applications and systems that require cooperation between different components.</p>
<p data-number="2"><strong>Resource Sharing</strong>: IPC facilitates <strong>resource sharing among processes</strong>. Operating systems often manage resources like files, I/O devices, and memory segments. IPC mechanisms allow processes to coordinate access to these shared resources, ensuring controlled and synchronized usage. Resource sharing prevents conflicts and enables efficient utilization of system resources by multiple processes.</p>
<p data-number="3"><strong>Synchronization</strong>: <strong>Process synchronization</strong> is a crucial objective of IPC. When processes share resources or data, they need to be synchronized to maintain data consistency and prevent race conditions. IPC mechanisms provide tools for process synchronization, allowing processes to coordinate their execution order, wait for specific events, and ensure that critical sections of code are executed atomically. Synchronization is vital for building reliable and predictable concurrent systems.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (a) (2 marks)</h3>
<div class="question-content">
<p>6. (a) Explain the term frame as applied in memory management.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>In memory management, a <strong>frame</strong> is a <strong>fixed-size block of physical memory (RAM)</strong>. When using paging, physical memory is divided into equal-sized blocks called frames. Frames are used to hold pages of processes that are loaded into physical memory. Frames are the basic units of physical memory allocation in paging systems.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (a) (4 marks)</h3>
<div class="question-content">
<p>(ii) Differentiate between base register and bound register as used in memory management.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Base Register</strong>:</p>
<p>A <strong>base register</strong>, in memory management with segmentation or base-limit registers, is a register that <strong>holds the starting physical address of a process's segment in memory</strong>. When a process is loaded into memory, the base address of its allocated segment is loaded into the base register. Every logical address generated by the process is added to the value in the base register to get the corresponding physical address. The base register defines the starting location of the process's memory region in physical RAM.</p>
<p><strong>Bound Register (Limit Register)</strong>:</p>
<p>A <strong>bound register</strong>, also known as a limit register, is used in conjunction with a base register to define the <strong>size or range of a process's memory segment</strong>. The bound register holds the <strong>size of the memory segment</strong> allocated to the process, or the value of the highest valid address relative to the base address. When a process generates a logical address, the operating system checks if the address is within the valid range defined by the bound register (i.e., logical address must be less than the bound). If the address is outside the bound, a memory protection fault (trap) occurs.</p>
<p><strong>Key Difference:</strong> The base register defines the starting address of a memory segment, while the bound register defines the size or limit of that segment. Together, they establish the valid memory range for a process and provide memory protection.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (b) (4 marks)</h3>
<div class="question-content">
<p>(b) Monolithic operating systems are not popular. Outline four limitations of monolithic operating systems that could be influencing this trend.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Lack of Modularity</strong>: <strong>Monolithic kernels lack modularity</strong>. All OS services (process management, memory management, file system, device drivers, etc.) are tightly integrated into a single, large kernel space. This makes the system complex to understand, maintain, and modify. Changes in one part of the kernel can have unintended consequences in other parts, increasing development and debugging difficulty.</p>
<p data-number="2"><strong>Large Kernel Size</strong>: Monolithic kernels tend to be <strong>very large in size</strong> as they include all OS functionalities in one executable. A large kernel consumes significant memory space and can increase the system's attack surface, making it more vulnerable to security exploits. Larger kernels also lead to increased boot times and can reduce the amount of memory available for user applications.</p>
<p data-number="3"><strong>System Instability</strong>: A fault in any part of a monolithic kernel can potentially <strong>crash the entire system</strong>. Because all services run in kernel space, errors in device drivers or any other kernel component can lead to system-wide failures. This lack of fault isolation makes monolithic systems less robust and reliable compared to more modular approaches.</p>
<p data-number="4"><strong>Portability Challenges</strong>: Monolithic kernels are often <strong>less portable across different hardware architectures</strong>. Due to the tight integration of all components, adapting a monolithic kernel to a new hardware platform can be complex and time-consuming. Changes often need to be made throughout the kernel, hindering portability and increasing development effort for supporting diverse hardware.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (c) (4 marks)</h3>
<div class="question-content">
<p>(c) With the aid of sketches, explain two issues associated with memory fragmentation.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) External Fragmentation</strong>:</p>
<p><strong>External fragmentation</strong> occurs when <strong>total free memory space is sufficient to satisfy a memory request, but it is not contiguous</strong>. Free memory is scattered in small, non-adjacent blocks between allocated memory regions. As processes are allocated and deallocated memory over time, external fragmentation can increase, making it impossible to allocate larger contiguous blocks, even when total free memory is adequate. This leads to wasted memory and reduced efficiency.</p>
<p><strong>Sketch of External Fragmentation:</strong></p>
<pre>+----------+---------+----------+---------+----------+
| Process A| Free    | Process B| Free    | Process C|  &lt;-- Non-contiguous free blocks
+----------+---------+----------+---------+----------+
       ^         ^         ^
       |         |         |
       Free Block 1 Free Block 2 Free Block 3

Total Free Memory = Free Block 1 + Free Block 2 + Free Block 3 (Sufficient in total, but not contiguous)
</pre>
<p><strong>(ii) Internal Fragmentation</strong>:</p>
<p><strong>Internal fragmentation</strong> occurs in fixed partitioning or paging systems where memory is allocated in fixed-size blocks (partitions or pages). When a process is allocated a partition or page that is larger than its actual memory requirement, the <strong>unused space within the allocated block is wasted and cannot be used by other processes</strong>. This wasted space within allocated partitions is internal fragmentation.</p>
<p><strong>Sketch of Internal Fragmentation:</strong></p>
<pre>+-----------------------+
| Process D (Uses part) | &lt;-- Process uses only a portion
+-----------------------+
| Wasted Memory        | &lt;-- Internally fragmented space within partition
+-----------------------+
       ^
       |
Allocated Partition (Fixed Size, Larger than Process D's Need)
</pre>
</div>
</div>
</section>
<section class="question">
<h3>6. (d) (6 marks)</h3>
<div class="question-content">
<p>(d) Maria intends to use round robin job scheduling algorithm in an operating system. Explain three benefits of using this algorithm.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Fairness</strong>: <strong>Round Robin (RR) scheduling</strong> is designed to be <strong>fair to all processes</strong>. It gives each process an equal share of CPU time by allocating a fixed time quantum to each process in a cyclic order. Every process gets a chance to run within a reasonable interval, preventing any process from being starved of CPU time. This fairness is particularly beneficial in time-sharing systems where multiple users or processes share the system.</p>
<p data-number="2"><strong>Responsiveness for Interactive Systems</strong>: RR scheduling provides <strong>good responsiveness for interactive systems</strong>. Because each process gets a small time quantum, interactive tasks, like user input processing or GUI updates, can be executed quickly and frequently. This results in short response times and a more interactive and user-friendly experience, as users do not experience long delays when interacting with applications.</p>
<p data-number="3"><strong>Easy to Implement</strong>: Round Robin is a <strong>relatively simple algorithm to implement</strong>. It only requires maintaining a ready queue and a timer to manage time quanta. The simplicity of RR scheduling reduces the overhead of scheduling decisions and makes it easier to integrate into operating systems. Its straightforward logic makes it less prone to implementation errors and easier to understand and debug compared to more complex scheduling algorithms.</p>
</div>
</div>
</section>
<section class="question">
<h3>7. (a) (i) (2 marks)</h3>
<div class="question-content">
<p>7. (a) (i) Outline two factors to be considered when selecting computer memory, other than cost.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Speed (Access Time)</strong>: <strong>Memory speed</strong>, often measured by access time or clock speed (for RAM), is a critical factor. Faster memory allows the CPU to fetch instructions and data more quickly, improving overall system performance. Different types of memory (e.g., DDR5 RAM vs. DDR4 RAM, SSD vs. HDD) offer varying speeds. Selecting memory with appropriate speed is essential to match the system's performance requirements.</p>
<p data-number="2"><strong>Capacity (Size)</strong>: <strong>Memory capacity</strong>, the amount of data that can be stored, is another key consideration. Sufficient memory capacity is necessary to run applications and handle data effectively. Insufficient memory can lead to performance bottlenecks, swapping, and system slowdowns. The required memory capacity depends on the intended workload and applications that will be run on the computer.</p>
</div>
</div>
</section>
<section class="question">
<h3>7. (a) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Differentiate between 1/0 bound and CPU bound jobs.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>I/O-Bound Jobs</strong>:</p>
<p><strong>I/O-bound jobs</strong> are processes where the <strong>rate at which the process progresses is primarily limited by the speed of I/O operations</strong>. These jobs spend a significant portion of their time waiting for I/O operations to complete (e.g., reading from disk, network communication, user input). The CPU is often idle while the process is waiting for I/O. Examples include file processing, network servers, and database applications.</p>
<p><strong>CPU-Bound Jobs</strong>:</p>
<p><strong>CPU-bound jobs</strong> are processes where the <strong>rate of progress is primarily limited by the speed of the CPU</strong>. These jobs require significant processing power and spend most of their time performing computations in the CPU. I/O operations are relatively infrequent compared to CPU computations. Examples include scientific simulations, video encoding, and complex calculations.</p>
<p><strong>Key Difference:</strong> I/O-bound jobs are limited by I/O speed and spend more time waiting for I/O, while CPU-bound jobs are limited by CPU speed and spend more time in computation.</p>
</div>
</div>
</section>
<section class="question">
<h3>7. (b) (i) (2 marks)</h3>
<div class="question-content">
<p>(b) (1) Define the term dispatcher as used in operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Dispatcher</strong>:</p>
<p>The <strong>dispatcher</strong> is a <strong>module within the operating system's short-term scheduler</strong> (CPU scheduler). It is responsible for the <strong>actual context switching</strong> of the CPU from one process to another. When the scheduler selects a process to run, the dispatcher takes over and performs the tasks needed to switch the CPU to the selected process. This includes saving the state of the previously running process and loading the saved state of the new process, effectively giving control of the CPU to the newly chosen process.</p>
</div>
</div>
</section>
<section class="question">
<h3>7. (b) (ii) (6 marks)</h3>
<div class="question-content">
<p>(ii) Describe three advantages of paging memory as used in memory management.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Elimination of External Fragmentation</strong>: <strong>Paging eliminates external fragmentation</strong>. Because memory is divided into fixed-size pages and frames, and processes are also divided into pages, memory allocation is always in units of pages and frames. There are no variable-sized partitions, so there are no gaps of free memory between allocated blocks that are too small to be used. Free frames can be allocated to any process page, regardless of their location in physical memory, thus preventing external fragmentation.</p>
<p data-number="2"><strong>Efficient Memory Utilization</strong>: Paging allows for more <strong>efficient memory utilization</strong> compared to segmentation or contiguous allocation. By using fixed-size pages, memory allocation and deallocation become simpler and more flexible. Only the necessary pages of a process need to be loaded into memory, and pages can be placed in any available frame. This reduces memory wastage and allows for a higher degree of multiprogramming, as memory can be used more effectively.</p>
<p data-number="3"><strong>Support for Virtual Memory</strong>: Paging is a fundamental technique for <strong>implementing virtual memory</strong>. It allows the operating system to create a virtual address space for each process that is larger than the physical RAM. Pages of a process can reside either in RAM (frames) or on disk (swap space). The operating system manages the swapping of pages between RAM and disk, enabling processes to run even if their total memory requirement exceeds the available physical memory. Virtual memory, enabled by paging, allows for running larger programs and increasing multiprogramming levels.</p>
</div>
</div>
</section>
<section class="question">
<h3>7. (c) (i) (2 marks)</h3>
<div class="question-content">
<p>(c) Lloyd was required to design a file system for a client that will support indiscriminate access of files by system users.</p>
<p>(i) Identify the most appropriate file access method that he could use justifying your answer.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Sequential Access Method</strong>:</p>
<p>The most appropriate file access method for indiscriminate access is the <strong>sequential access method</strong>. In sequential access, files are accessed in a <strong>linear, ordered fashion, from the beginning to the end</strong>. This method is simple to implement and understand, and it inherently supports indiscriminate access because any user can read through the file from start to finish without restrictions on access order.</p>
</div>
</div>
</section>
<section class="question">
<h3>7. (c) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Explain two advantages of file access method identified in (i).</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Simplicity and Ease of Implementation</strong>: The <strong>sequential access method</strong> is very <strong>simple to implement and understand</strong>. It requires minimal overhead in terms of file system structures and algorithms. Files are simply read from start to end, which is straightforward to manage. This simplicity reduces the complexity of file system design and implementation, making it easier to develop and maintain.</p>
<p data-number="2"><strong>Efficiency for Certain Applications</strong>: For applications that process files in a <strong>sequential manner</strong>, such as batch processing, log file analysis, or streaming data, sequential access is highly <strong>efficient</strong>. Reading files in order eliminates the need for random seeks or complex indexing, resulting in faster read operations for these types of applications. It is well-suited for scenarios where data is processed in a linear flow from beginning to end.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (a) (4 marks)</h3>
<div class="question-content">
<p>8. (a) Figure 1 shows a sketch of a section of a hard disk.</p>
<p><img src="Screenshot_2025-03-12_at_12-14-48_2016nov.pdf.png" alt="" width="371" height="252" /></p>
<p>Explain the functions of each of the parts labeled (i) and (ii).</p>
<p><img src="paperpaper-004.png" alt="Figure 1" /></p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>Based on the typical structure of a hard disk sketch, assuming (i) is pointing to the circular platters and (ii) is pointing to the read/write heads:</p>
<p><strong>(i) Platters</strong>:</p>
<p>The <strong>platters</strong> are the <strong>circular magnetic disks</strong> that are the fundamental data storage components of a hard disk drive. Data is <strong>recorded magnetically on the surfaces of these platters</strong>. Modern hard disks typically have multiple platters stacked on a spindle. Each platter surface is divided into tracks, sectors, and cylinders. The platters rotate at high speeds, allowing the read/write heads to access data sectors. The magnetic material on the platters retains data even when power is off, providing non-volatile storage.</p>
<p><strong>(ii) Read/Write Heads</strong>:</p>
<p>The <strong>read/write heads</strong> are small electromagnetic components that are positioned just above the platters' surfaces. Their function is to <strong>read data from and write data to the magnetic platters</strong>. Each platter surface has a dedicated read/write head. When writing data, the heads magnetize the platter surface to represent binary data. When reading, they detect the magnetic patterns on the platter to retrieve stored data. The heads move radially across the platters to access different tracks and sectors. They operate very close to the platter surface but do not touch it during normal operation, floating on a thin air cushion.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (b) (4 marks)</h3>
<div class="question-content">
<p>(b) Dennis investigated challenges faced while using non-preemptive job scheduling in operating systems. Explain two challenges that he could have established.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Poor Responsiveness for Interactive Tasks</strong>: <strong>Non-preemptive scheduling</strong> can lead to <strong>poor responsiveness for interactive tasks</strong>. Once a process is given the CPU, it runs until it voluntarily releases the CPU by completing its CPU burst or performing I/O. If a long-running process is executing, interactive processes or high-priority tasks have to wait until the current process finishes. This can result in noticeable delays and a sluggish user experience, especially in interactive environments.</p>
<p data-number="2"><strong>Risk of Starvation</strong>: Non-preemptive scheduling can lead to a <strong>risk of starvation for shorter or I/O-bound processes</strong>. If there is a continuous stream of long-running CPU-bound processes, shorter processes or I/O-bound processes might have to wait for extended periods before getting CPU time. This can result in unfair resource allocation and potential starvation, where some processes are indefinitely delayed from getting CPU access.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (c) (4 marks)</h3>
<div class="question-content">
<p>(c) Bernard intends to configure access control list (ACI) in a one of his client's file system. Explain two reasons that could influence his decision.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Enhanced File System Security</strong>: Implementing Access Control Lists (ACLs) provides <strong>enhanced file system security</strong>. ACLs allow for fine-grained control over file and directory access permissions. Instead of basic owner-group-others permissions, ACLs enable administrators to define specific access rights (read, write, execute, delete, etc.) for individual users or groups for each file and directory. This granular control improves security by allowing precise permission settings, minimizing unauthorized access and protecting sensitive data more effectively.</p>
<p data-number="2"><strong>Flexible Access Management</strong>: ACLs offer <strong>flexible access management</strong>. They go beyond traditional permission models by allowing the assignment of permissions to multiple users and groups, not just owner, group, and others. This flexibility is crucial in complex environments where different users or groups need varying levels of access to different files and directories. ACLs simplify the management of complex permission scenarios, making it easier to grant appropriate access rights based on organizational needs and security policies.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (d) (i) (4 marks)</h3>
<div class="question-content">
<p>(d) (i) Cindy was required to indentify characteristics of a 4th generation operating system during an exam. Outline four characteristics that she could have listed.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Large Scale Integration (LSI) and Very Large Scale Integration (VLSI) Technology</strong>: 4th generation operating systems were developed alongside the advent of <strong>LSI and VLSI technology</strong> in hardware. This allowed for more powerful and compact processors and memory, enabling more complex and feature-rich operating systems. The increased processing power and memory capacity facilitated the development of advanced OS features.</p>
<p data-number="2"><strong>Graphical User Interfaces (GUIs)</strong>: The 4th generation saw the widespread adoption of <strong>Graphical User Interfaces (GUIs)</strong>. Operating systems like macOS and Windows introduced user-friendly, icon-based interfaces, making computers more accessible to non-technical users. GUIs replaced command-line interfaces for many common tasks, enhancing user experience and productivity.</p>
<p data-number="3"><strong>Personal Computing and Workstations</strong>: 4th generation OSs were designed for <strong>personal computers and workstations</strong>. They focused on providing user-centric features, supporting single-user interactive computing, and catering to individual productivity needs. These operating systems were tailored for desktop environments and individual user applications.</p>
<p data-number="4"><strong>Networking and Distributed Systems Support</strong>: Networking capabilities and support for <strong>distributed systems</strong> became prominent in 4th generation OSs. Features for network communication, file sharing, and client-server computing were integrated. Operating systems started to support network protocols and services, enabling computers to connect and communicate in networks and distributed environments.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (d) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) RDS Company Ltd. intends to deploy Redundant Array of Independent Disks (RAID) in its file system. Explain two benefits that the company could realize from using the technology.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Improved Data Reliability and Fault Tolerance</strong>: <strong>RAID (Redundant Array of Independent Disks)</strong> significantly improves <strong>data reliability and fault tolerance</strong>. By using techniques like mirroring (RAID 1) or striping with parity (RAID 5, RAID 6), RAID provides redundancy. If one disk in the array fails, data can be recovered or continued to be accessed from the remaining disks. This redundancy minimizes data loss and system downtime due to disk failures, enhancing data integrity and system availability, which is crucial for business continuity.</p>
<p data-number="2"><strong>Enhanced Performance (in some RAID levels)</strong>: Certain RAID levels, such as <strong>RAID 0 (striping) and RAID 5/6 (striping with parity)</strong>, can improve <strong>I/O performance</strong>. RAID 0 stripes data across multiple disks, allowing for parallel read and write operations, which can significantly increase data transfer rates and reduce access times. RAID 5 and RAID 6 also offer performance benefits for read operations due to data striping. Enhanced performance, especially for I/O intensive applications, can improve application responsiveness and overall system efficiency.</p>
</div>
</div>
</section>
</main></p>
<p></p>
<p></p>
<footer>©2016 The Kenya National Examinations Council.</footer></div>
</div>
</div>
</article>
</section>
</div>
<div id='bottomPagination'>
<nav class="pagination noprt">
<a href="july_2017.html" class="prev"><span><span>&laquo; </span>Previous</span></a> <span class="sep">| </span><a href="july_2016.html" class="next"><span>Next<span> &raquo;</span></span></a>
</nav>
</div>
</div>
<script type="text/javascript" src="_intef_js.js"></script></body></html>