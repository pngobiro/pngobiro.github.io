<!doctype html>
<html lang="en">
<head>
<link rel="stylesheet" type="text/css" href="base.css" />
<link rel="stylesheet" type="text/css" href="content.css" />
<link rel="stylesheet" type="text/css" href="nav.css" />
<meta http-equiv="content-type" content="text/html;  charset=utf-8" />
<title>November 2012 </title>
<link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<meta name="generator" content="eXeLearning 2.9 - exelearning.net" />
<!--[if lt IE 9]><script type="text/javascript" src="exe_html5.js"></script><![endif]-->
<script type="text/javascript" src="exe_jquery.js"></script>
<script type="text/javascript" src="common_i18n.js"></script>
<script type="text/javascript" src="common.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
</head>
<body class="exe-web-site" id="exe-node-16"><script type="text/javascript">document.body.className+=" js"</script>
<div id="content">
<p id="skipNav"><a href="#main" class="sr-av">Skip navigation</a></p>
<section id="emptyHeader"></section>
<nav id="siteNav">
<ul>
   <li><a href="index.html" class="daddy main-node">Home</a></li>
   <li><a href="july_2023.html" class="no-ch">July 2023</a></li>
   <li><a href="november_2021.html" class="no-ch">November 2021</a></li>
   <li><a href="july_2021.html" class="no-ch">July 2021</a></li>
   <li><a href="july_2019.html" class="no-ch">July 2019</a></li>
   <li><a href="november_2018.html" class="no-ch">November 2018</a></li>
   <li><a href="november_2017.html" class="no-ch">November 2017</a></li>
   <li><a href="july_2017.html" class="no-ch">July 2017</a></li>
   <li><a href="november_2016.html" class="no-ch">November 2016</a></li>
   <li><a href="july_2016.html" class="no-ch">July 2016</a></li>
   <li><a href="november_2015.html" class="no-ch">November 2015</a></li>
   <li><a href="july_2015.html" class="no-ch">July 2015</a></li>
   <li><a href="novemeber_2014.html" class="no-ch">Novemeber 2014</a></li>
   <li><a href="july_2014.html" class="no-ch">July 2014</a></li>
   <li><a href="november_2013.html" class="no-ch">November 2013</a></li>
   <li><a href="july_2013.html" class="no-ch">July 2013</a></li>
   <li id="active"><a href="november_2012.html" class="active no-ch">November 2012</a></li>
   <li><a href="july_2012.html" class="no-ch">July 2012</a></li>
   <li><a href="july_2011.html" class="no-ch">July 2011</a></li>
</ul>
</nav>
<div id='topPagination'>
<nav class="pagination noprt">
<a href="july_2013.html" class="prev"><span><span>&laquo; </span>Previous</span></a> <span class="sep">| </span><a href="july_2012.html" class="next"><span>Next<span> &raquo;</span></span></a>
</nav>
</div>
<div id="main-wrapper">
<section id="main">
<header id="nodeDecoration"><h1 id="nodeTitle">November 2012</h1></header>
<article class="iDevice_wrapper textIdevice" id="id16">
<div class="iDevice emphasis0" >
<div id="ta16_138_2" class="block iDevice_content">
<div class="exe-text"><p></p>
<style>
        /* Modern CSS Reset */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        /* Base Styles */
        body {
            font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;
            line-height: 1.6;
            color: #2d3748;
            background-color: #f7fafc;
            margin: 0;
            padding: 0;
        }

        /* Header Styles */
        header {
            background: linear-gradient(135deg, #1a365d 0%, #2c5282 100%);
            color: white;
            padding: 2rem;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        header h1 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
            font-weight: 600;
        }

        .exam-details {
            background: rgba(255, 255, 255, 0.1);
            padding: 1rem;
            border-radius: 8px;
            display: inline-block;
            margin-top: 1rem;
        }

        .exam-details p {
            margin: 0.5rem 0;
            font-size: 1.1rem;
        }

        /* Main Content */
        main {
            max-width: 1200px;
            margin: 2rem auto;
            padding: 0 1.5rem;
        }

        /* Passage Styles */
        .passage {
            background: #edf2f7;
            border-radius: 12px;
            margin-bottom: 2rem;
            padding: 1.5rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
        }

        .passage h2 {
            color: #2d3748;
            margin-bottom: 1rem;
            font-size: 1.5rem;
            border-bottom: 2px solid #cbd5e0;
            padding-bottom: 0.5rem;
        }

        .passage-content {
            font-size: 1.1rem;
            color: #4a5568;
            line-height: 1.8;
        }

        .passage-content p {
            margin-bottom: 1rem;
        }

        /* Question Styles */
        .question {
            background: white;
            border-radius: 12px;
            margin-bottom: 2rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
            overflow: hidden;
        }

        .question h3 {
            background: #4a5568;
            color: white;
            padding: 1rem 1.5rem;
            font-size: 1.25rem;
            margin: 0;
            border-bottom: 3px solid #2d3748;
        }

        .question-content {
            padding: 1.5rem;
            background: #fff;
            border-bottom: 2px solid #edf2f7;
        }

        .question-content p {
            font-size: 1.1rem;
            color: #2d3748;
        }

        /* Answer Styles */
        .answer-section {
            background: #f8fafc;
            border-top: 2px solid #e2e8f0;
        }

        .answer-section h4 {
            padding: 1rem 1.5rem;
            color: #2d3748;
            font-size: 1.2rem;
            background: #edf2f7;
            margin: 0;
        }

        .answer-content {
            padding: 1.5rem;
            color: #4a5568;
        }

        .answer-content p {
            margin-bottom: 1rem;
            line-height: 1.8;
        }

        /* Bold Answers */
        .answer-content strong, .answer-content b {
            color: #2d3748;
            font-weight: 700;
        }

        /* Numbered Lists in Answers */
        .answer-content p[data-number]:before {
            content: attr(data-number) ".";
            font-weight: 600;
            margin-right: 0.5rem;
            color: #4a5568;
        }

        /* Table Styles */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
            overflow: hidden;
            border-radius: 8px;
        }

        thead {
            background-color: #4a5568;
            color: white;
        }

        th {
            text-align: left;
            padding: 0.75rem 1rem;
            font-weight: 600;
            border-bottom: 2px solid #2d3748;
        }

        td {
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            background-color: white;
        }

        tr:last-child td {
            border-bottom: none;
        }

        tr:nth-child(even) td {
            background-color: #f8fafc;
        }

        /* Footer Styles */
        footer {
            background: #2d3748;
            color: white;
            text-align: center;
            padding: 1.5rem;
            margin-top: 3rem;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            header h1 {
                font-size: 2rem;
            }

            main {
                padding: 0 1rem;
            }

            .passage h2 {
                font-size: 1.3rem;
            }

            .passage-content p {
                font-size: 1rem;
            }

            .question {
                margin-bottom: 1.5rem;
            }

            .question h3 {
                font-size: 1.1rem;
            }

            .question-content p,
            .answer-content p {
                font-size: 1rem;
            }
            
            table, thead, tbody, th, td, tr {
                display: block;
            }
            
            thead tr {
                position: absolute;
                top: -9999px;
                left: -9999px;
            }
            
            tr {
                border: 1px solid #e2e8f0;
                margin-bottom: 1rem;
                border-radius: 8px;
                overflow: hidden;
            }
            
            td {
                border: none;
                position: relative;
                padding-left: 50%;
                text-align: left;
                border-bottom: 1px solid #e2e8f0;
            }
            
            td:before {
                position: absolute;
                top: 0.75rem;
                left: 1rem;
                width: 45%;
                padding-right: 10px;
                white-space: nowrap;
                font-weight: 600;
                content: attr(data-label);
            }
            
            td:last-child {
                border-bottom: 0;
            }
        }

        /* Print Styles */
        @media print {
            body {
                background: white;
            }

            .passage,
            .question {
                break-inside: avoid;
                box-shadow: none;
                border: 1px solid #edf2f7;
            }

            header {
                background: white;
                color: black;
                padding: 1rem;
            }

            .exam-details {
                border: 1px solid #edf2f7;
            }
            
            table {
                break-inside: auto;
            }
            
            tr {
                break-inside: avoid;
                break-after: auto;
            }
        }
    </style>
<header>
<h1>OPERATING SYSTEMS</h1>
<div class="exam-details">
<p>Exam Code: 2920/105</p>
<p>Duration: 3 hours</p>
<p>Period: November 2012</p>
</div>
</header>
<p></p>
<p></p>
<p><main>
<section class="question">
<h3>1. (a) (i) (2 marks)</h3>
<div class="question-content">
<p>Outline two roles for each of the following computer components in operating systems:</p>
<p>(i) processor:</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Instruction Execution</strong>: The <strong>processor</strong>, or CPU, is responsible for <strong>executing instructions</strong> of programs that constitute the operating system and user applications. It fetches instructions from memory, decodes them, and performs the operations specified, which are fundamental to all computing tasks.</p>
<p data-number="2"><strong>Process Management</strong>: The processor, under the control of the operating system, <strong>manages and executes processes</strong>. It allocates CPU time to different processes, switches between them to enable multitasking, and ensures fair and efficient utilization of the processing resource.</p>
</div>
</div>
</section>
<section class="question">
<h3>1. (a) (ii) (2 marks)</h3>
<div class="question-content">
<p>Outline two roles for each of the following computer components in operating systems:</p>
<p>(ii) RAM.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Storing Running Programs and Data</strong>: <strong>RAM (Random Access Memory)</strong> serves as the <strong>primary memory</strong> for actively running programs and the data they are currently using. The operating system loads program code and data into RAM for quick access by the processor, enabling efficient execution of applications.</p>
<p data-number="2"><strong>Temporary Storage for OS Operations</strong>: RAM provides <strong>temporary storage</strong> for the operating system itself during its operation. The kernel, device drivers, and other OS components reside in RAM while the system is running, allowing the OS to manage system resources, handle interrupts, and perform other essential functions.</p>
</div>
</div>
</section>
<section class="question">
<h3>1. (b) (i) (2 marks)</h3>
<div class="question-content">
<p>A group of Module II students were carrying out research on types of operating systems. They listed the following features of a certain type of an operating system:</p>
<ul>
<li>allows multiple users to simultaneously access the system through terminals.</li>
<li>supports collection of autonomous computers connected through network.</li>
<li>supports sharing of data and resources.</li>
</ul>
<p>(i) Identify the most appropriate type of operating system that exhibited these features justifying your answer.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>The most appropriate type of operating system exhibiting these features is a <strong>Distributed Operating System</strong>. This is justified because the features listed - support for multiple users accessing the system simultaneously, collection of autonomous computers connected through a network, and sharing of data and resources - are characteristic of distributed systems where resources and processing are spread across multiple computers working together as a single system image.</p>
</div>
</div>
</section>
<section class="question">
<h3>1. (b) (ii) (4 marks)</h3>
<div class="question-content">
<p>A group of Module II students were carrying out research on types of operating systems. They listed the following features of a certain type of an operating system:</p>
<ul>
<li>allows multiple users to simultaneously access the system through terminals.</li>
<li>supports collection of autonomous computers connected through network.</li>
<li>supports sharing of data and resources.</li>
</ul>
<p>(ii) Explain two advantages of the type of operating system identified in (1).</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Resource Sharing</strong>: A <strong>Distributed Operating System</strong> excels at <strong>resource sharing</strong>. It allows users across different computers in the network to access and utilize resources such as files, printers, databases, and processing power as if they were on a single machine. This enhances efficiency and reduces redundancy by pooling resources and making them available to a wider user base, optimizing overall resource utilization.</p>
<p data-number="2"><strong>Enhanced Reliability and Fault Tolerance</strong>: Distributed systems offer <strong>enhanced reliability and fault tolerance</strong>. Because processing and resources are spread across multiple independent computers, the failure of one computer does not necessarily bring down the entire system. If one node fails, tasks can be redistributed to other nodes, ensuring continuous operation and minimizing downtime. This redundancy and resilience improve the overall robustness and availability of the system.</p>
</div>
</div>
</section>
<section class="question">
<h3>1. (c) (i) (2 marks)</h3>
<div class="question-content">
<p>(i) Explain the term kernel as used in operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>The <strong>kernel</strong> is the <strong>core component</strong> of an operating system. It is the <strong>innermost layer</strong> of the OS and has direct control over the hardware. The kernel provides essential services such as process management, memory management, device management, and system calls. It acts as a bridge between the hardware and user-level software, managing system resources and ensuring secure and efficient operation of the computer.</p>
</div>
</div>
</section>
<section class="question">
<h3>1. (c) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Differentiate between block-oriented and stream-oriented VO devices.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Block-Oriented I/O Devices</strong>:</p>
<p><strong>Block-oriented I/O devices</strong> transfer data in <strong>fixed-size blocks</strong>. Data is structured into blocks, and I/O operations are performed on these entire blocks at a time. These devices typically have <strong>addressable blocks</strong>, allowing for random access to any block in the device. Examples of block-oriented devices include <strong>hard disks, SSDs, and tapes</strong> (when used in block mode). Data transfer with block devices is usually buffered and may involve seek operations to locate specific blocks. Block devices are suitable for applications requiring structured data storage and random access, such as file systems and databases.</p>
<p><strong>Stream-Oriented I/O Devices</strong>:</p>
<p><strong>Stream-oriented I/O devices</strong> transfer data as a <strong>continuous stream of bytes or characters</strong>, without any fixed block structure. Data is processed and transferred sequentially, and there is typically no concept of addressable blocks or random access. Examples of stream-oriented devices include <strong>keyboards, mice, printers, and network interfaces</strong>. Data transfer with stream devices is usually unbuffered or minimally buffered and is processed as a continuous flow. Stream devices are suitable for character-based input/output, communication, and real-time data streams where the sequence of data is important.</p>
<p><strong>Key Distinction</strong>:</p>
<p>The primary difference lies in how data is organized and transferred. <strong>Block-oriented devices</strong> use fixed-size blocks and allow random access, while <strong>stream-oriented devices</strong> use continuous byte streams and are typically accessed sequentially. Block devices are for structured storage, and stream devices are for continuous data flow.</p>
</div>
</div>
</section>
<section class="question">
<h3>1. (d) (4 marks)</h3>
<div class="question-content">
<p>(d) Susan was required to configure RAID on a computer system that contained two hard disks. Explain two most appropriate type of RAID she could use.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>RAID 1 (Mirroring)</strong>: <strong>RAID 1</strong> is a highly appropriate choice for a system with two hard disks as it provides <strong>data redundancy and fault tolerance</strong>. In RAID 1, data is mirrored across both disks, meaning an exact copy of the data is written to each disk. If one disk fails, the system can continue to operate using the remaining disk without data loss. RAID 1 is simple to implement with two disks and offers excellent data protection, making it suitable for scenarios where data reliability is paramount. However, it reduces the effective storage capacity by half, as one disk's capacity is used for mirroring.</p>
<p data-number="2"><strong>RAID 0 (Striping)</strong>: Although RAID 0 does not provide fault tolerance, it is appropriate if Susan's primary goal is to <strong>improve performance</strong>. RAID 0 stripes data across both disks, meaning data is split into segments and written alternately across the two disks. This allows for <strong>parallel read and write operations</strong>, potentially doubling the data transfer rate compared to a single disk. RAID 0 is simple to implement with two disks and maximizes storage capacity and performance. However, it offers no redundancy; if either disk fails, all data is lost. Therefore, RAID 0 is suitable only if data loss is acceptable or if backups are managed separately, and performance is the main concern.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (a) (i) (2 marks)</h3>
<div class="question-content">
<p>2. (a) (i) Outline two objectives of developing an operating system.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Resource Management</strong>: One primary objective is to <strong>manage computer hardware and software resources efficiently and effectively</strong>. This includes managing the CPU, memory, I/O devices, and files. The OS aims to allocate resources fairly among different processes and users, optimize resource utilization, and prevent conflicts to ensure smooth system operation.</p>
<p data-number="2"><strong>User Convenience and Interface</strong>: Another key objective is to provide a <strong>user-friendly and convenient interface</strong> for users to interact with the computer system. The OS should simplify complex hardware operations and provide abstractions that make it easier for users to run applications, manage files, and perform tasks. A good OS aims to enhance user productivity and experience by providing intuitive and efficient ways to use the computer.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (a) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Differentiate between SJF and FCFS process scheduling algorithms.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Shortest Job First (SJF) Scheduling Algorithm</strong>:</p>
<p><strong>SJF (Shortest Job First)</strong> is a process scheduling algorithm that selects the process with the <strong>shortest estimated burst time</strong> (CPU execution time) to run next. SJF aims to minimize the average waiting time and turnaround time of processes. It can be <strong>preemptive or non-preemptive</strong>. In its non-preemptive version, once a process starts, it runs to completion. In the preemptive version (Shortest Remaining Time First - SRTF), a running process can be preempted if a new process arrives with a shorter remaining burst time. SJF is optimal in minimizing average waiting time but requires knowing or estimating the burst time of processes in advance, which can be challenging in practice.</p>
<p><strong>First Come First Served (FCFS) Scheduling Algorithm</strong>:</p>
<p><strong>FCFS (First Come First Served)</strong> is the simplest process scheduling algorithm. It schedules processes in the <strong>order of their arrival</strong> in the ready queue. The process that arrives first gets the CPU first. FCFS is <strong>non-preemptive</strong>; once a process starts running, it continues until it completes or blocks for I/O. FCFS is easy to implement and understand but can lead to <strong>convoy effect</strong>, where a long-running process blocks shorter processes behind it, resulting in higher average waiting and turnaround times, especially if processes arrive in a non-optimal order (e.g., long process arrives first).</p>
<p><strong>Key Distinction</strong>:</p>
<p>The main difference is in their scheduling criteria. <strong>SJF</strong> prioritizes processes with the shortest burst time to minimize average waiting time, while <strong>FCFS</strong> prioritizes processes based on their arrival order, regardless of their burst times. SJF is generally more efficient in terms of average waiting time but is more complex to implement and requires burst time estimation, whereas FCFS is simple but can be inefficient, especially with varying process lengths.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (b) (i) (2 marks)</h3>
<div class="question-content">
<p>(b) (i) State four process states in an operating system.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>New</strong>: The process is being <strong>created</strong>.</p>
<p data-number="2"><strong>Ready</strong>: The process is <strong>ready to run</strong> but waiting for the CPU to be allocated.</p>
<p data-number="3"><strong>Running</strong>: The process is <strong>currently being executed</strong> by the CPU.</p>
<p data-number="4"><strong>Waiting (or Blocked)</strong>: The process is <strong>waiting for an event</strong> to occur, such as I/O completion or resource availability.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (b) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Explain two benefits of using round robin scheduling algorithm in operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Fairness</strong>: <strong>Round Robin (RR)</strong> provides <strong>fair allocation of CPU time</strong> to all processes. Each process gets a fixed time slice (quantum) of CPU time in turns. This prevents starvation, ensuring that all processes, regardless of their priority or burst time, eventually get a chance to run. Fairness is particularly important in time-sharing systems where multiple users or interactive applications are running concurrently, as it ensures that no single process monopolizes the CPU.</p>
<p data-number="2"><strong>Responsiveness and Good for Interactive Systems</strong>: RR offers <strong>good responsiveness</strong>, especially for interactive systems. Because each process gets a time slice regularly, even if it's a long process, the system remains responsive to user inputs and interactive tasks. Short processes can complete quickly, and long processes make steady progress without causing the system to become sluggish. This makes RR suitable for environments where users expect quick feedback and smooth interaction with applications.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (c) (4 marks)</h3>
<div class="question-content">
<p>(c) With the aid of a diagram, outline the client server structure of an operating system.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>The <strong>Client-Server structure of an Operating System</strong> separates the operating system functionalities into two main parts: the <strong>client</strong> and the <strong>server</strong>. The <strong>microkernel</strong> acts as the core, providing minimal essential services, and other OS services are implemented as user-level servers that clients communicate with.</p>
<p><strong>Diagram of Client-Server OS Structure:</strong></p>
<pre>                    +-----------------------+   +-----------------------+   +-----------------------+  ... User Processes (Clients)
                    |     Client Process    |   |     Client Process    |   |     Client Process    |
                    +-----------------------+   +-----------------------+   +-----------------------+
                                  |                                   |                                   |
                                  +-----------------------------------+-----------------------------------+-------------------&gt; Message Passing (Requests)
                                                        |
                                                        v
                                        +---------------------------------------+
                                        |               Microkernel               |
                                        | (Process Management, IPC, Memory Mgmt) |
                                        +---------------------------------------+
                                                        ^
                                                        | Message Passing (Responses)
                                  +-----------------------------------+-----------------------------------+-------------------
                                  |     File Server         |   |     Print Server        |   |     Network Server      | ... OS Services (Servers)
                                  +-----------------------+   +-----------------------+   +-----------------------+
                    </pre>
<p><strong>Description:</strong></p>
<p><strong>Microkernel</strong>: The <strong>microkernel</strong> is the minimal core of the OS, containing only essential functionalities such as <strong>process management, inter-process communication (IPC), and basic memory management</strong>. It is kept small and simple to enhance reliability and security.</p>
<p><strong>User-Level Servers (OS Services)</strong>: Most traditional OS services, such as <strong>file systems, device drivers, network services, and print services</strong>, are implemented as <strong>user-level server processes</strong> that run on top of the microkernel. These servers operate in user mode, separate from the kernel's privileged mode.</p>
<p><strong>Client Processes</strong>: <strong>User applications and processes</strong> act as <strong>clients</strong>. When a client process needs an OS service (e.g., file I/O, network access), it sends a <strong>request message</strong> to the appropriate server process through the microkernel's IPC mechanism.</p>
<p><strong>Message Passing Communication</strong>: Clients and servers communicate by <strong>exchanging messages</strong> through the microkernel. The client sends a request message to the server, the server processes the request, and sends a <strong>response message</strong> back to the client. All communication is mediated by the microkernel.</p>
<p>This structure promotes modularity, extensibility, and fault isolation. Server failures are less likely to crash the entire system as servers run in user mode, and the microkernel remains protected.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (d) (4 marks)</h3>
<div class="question-content">
<p>(d) Mary, a secretary with a certain company used operating systems to create directories for various lecturers. Outline four benefits of Mary's approach.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Organization of Files</strong>: Creating directories allows for <strong>better organization of files</strong>. Mary can categorize and group files related to each lecturer within their respective directories. This makes it easier to locate and manage files, preventing a cluttered and disorganized file system, and improving overall file management efficiency.</p>
<p data-number="2"><strong>Reduced Naming Conflicts</strong>: Directories help in <strong>reducing file naming conflicts</strong>. Mary can use the same file names for different lecturers as long as they are within different directories. For example, she can have "Notes.docx" in each lecturer's directory without conflict. This is not possible in a flat, single-level directory, where all file names must be unique.</p>
<p data-number="3"><strong>Improved Access Control and Security</strong>: Directories facilitate <strong>better access control and security</strong>. Mary can set permissions on each directory to control who can access, modify, or delete files within that directory. This allows for restricting access to lecturers' files, ensuring that only authorized personnel can access or modify specific files, enhancing data security and privacy.</p>
<p data-number="4"><strong>Simplified File Sharing and Collaboration</strong>: Directories can simplify <strong>file sharing and collaboration</strong>. Mary can easily share a specific directory with a lecturer, granting them access to all files within that directory. This streamlines the process of sharing files related to a particular lecturer, making collaboration more efficient and organized compared to sharing individual files scattered across a flat file system.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (a) (3 marks)</h3>
<div class="question-content">
<p>3. (a) Outline three file access methods that could be used in an operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Sequential Access</strong>: In <strong>sequential access</strong>, files are accessed in a <strong>linear order</strong>, from the beginning to the end. To access a specific record, one must read through all preceding records. This method is simple and efficient for processing files in order, like reading a log file.</p>
<p data-number="2"><strong>Direct (Random) Access</strong>: In <strong>direct access</strong>, also known as random access, any record in a file can be accessed <strong>directly without reading preceding records</strong>. This is achieved by using a record number or key to calculate the record's location. Direct access is suitable for applications needing quick access to specific records, like databases.</p>
<p data-number="3"><strong>Indexed Sequential Access</strong>: <strong>Indexed sequential access</strong> combines sequential and direct access. It uses an <strong>index</strong> to enable direct access to records, but also allows for efficient sequential processing. The index provides a lookup mechanism for direct access, while the sequential organization supports ordered processing.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (b) (7 marks)</h3>
<div class="question-content">
<p>(b) With the aid of a diagram, outline the five levels of typical file systems architecture as used in operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>The <strong>five levels of a typical file system architecture</strong> in operating systems represent a layered approach to file management, from the physical storage to the user interface.</p>
<p><strong>Diagram of Five-Level File System Architecture:</strong></p>
<pre>                    +-----------------------+  Level 5: User Application Layer
                    | User Applications     |  (File operations: read, write, open, close)
                    +-----------------------+
                    | Logical File System   |  Level 4: Logical File System Layer
                    | (File naming, directory structure, access control)
                    +-----------------------+
                    | File-Organization     |  Level 3: File Organization Layer
                    | Module                |  (Logical-to-physical address mapping, file metadata management)
                    +-----------------------+
                    | Basic File System     |  Level 2: Basic File System Layer
                    | (Generic commands to device drivers: read block, write block)
                    +-----------------------+
                    | I/O Control           |  Level 1: I/O Control Layer
                    | (Device drivers, hardware interaction)
                    +-----------------------+
                    | Storage Media         |  Level 0: Storage Media Layer
                    | (Disk, SSD, etc.)     |
                    +-----------------------+
                    </pre>
<p><strong>Description of Levels:</strong></p>
<p><strong>Level 5: User Application Layer</strong>: This is the <strong>highest level</strong>, where user applications interact with the file system. Applications use <strong>system calls</strong> (e.g., `open`, `read`, `write`, `close`) to perform file operations. This layer is concerned with user-level file access and operations.</p>
<p><strong>Level 4: Logical File System Layer</strong>: This layer, also known as the <strong>file system interface</strong>, provides the <strong>logical view</strong> of the file system to users and applications. It handles <strong>file naming, directory structure, file metadata (attributes), and access control</strong>. It translates user-level file operations into logical operations that the lower layers can understand.</p>
<p><strong>Level 3: File Organization Module</strong>: This layer is responsible for <strong>mapping logical file addresses to physical block addresses</strong> on storage devices. It manages <strong>file metadata</strong> (like file headers, inodes, or file allocation tables) that track the location of file blocks on disk. It deals with file allocation strategies, free space management, and logical-to-physical address translation.</p>
<p><strong>Level 2: Basic File System Layer</strong>: This layer, sometimes called the <strong>file system proper</strong>, provides <strong>basic file system commands</strong> to interact with device drivers. It issues generic commands like "read block," "write block," and "allocate block" to the I/O control layer, abstracting away device-specific details. It focuses on block-level operations and management.</p>
<p><strong>Level 1: I/O Control Layer</strong>: This is the <strong>lowest software layer</strong>, consisting of <strong>device drivers</strong>. It interacts directly with the <strong>hardware controllers</strong> of storage devices. Device drivers translate generic block-level requests from the basic file system into device-specific commands that the hardware can understand and execute. It handles hardware-specific I/O operations and interrupt handling.</p>
<p><strong>Level 0: Storage Media Layer</strong>: This is the <strong>physical storage medium</strong> itself, such as <strong>hard disks, SSDs, or other storage devices</strong>, where the actual file data is stored in physical blocks or sectors.</p>
<p>This layered architecture provides abstraction, modularity, and device independence, making file system management organized and efficient.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (c) (i) (2 marks)</h3>
<div class="question-content">
<p>(c) (i) Outline two goals of memory management in operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Efficient Memory Utilization</strong>: A primary goal is to <strong>utilize memory efficiently</strong> to accommodate as many processes as possible and minimize wasted memory space. Techniques like dynamic allocation, virtual memory, and paging are used to optimize memory usage and improve system throughput by reducing fragmentation and overhead.</p>
<p data-number="2"><strong>Address Translation and Protection</strong>: Memory management aims to provide <strong>address translation</strong> from logical to physical addresses, allowing processes to have their own virtual address space, and to implement <strong>memory protection</strong>. Protection ensures that processes cannot access memory outside their allocated space, preventing interference and enhancing system stability and security.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (c) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Differentiate between device drivers and device I/O as used in operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Device Drivers</strong>:</p>
<p><strong>Device drivers</strong> are <strong>software modules</strong> that act as an <strong>interface between the operating system kernel and specific hardware devices</strong>. They are device-specific and provide the low-level control and communication necessary for the OS to interact with hardware. Device drivers translate generic I/O requests from the kernel into device-specific commands that the hardware controller can understand. They handle hardware-specific operations, manage device registers, and handle interrupts from devices. Device drivers are essential for achieving device independence, allowing the OS to support a variety of hardware without modifying the core OS code.</p>
<p><strong>Device I/O</strong>:</p>
<p><strong>Device I/O (Input/Output)</strong> refers to the <strong>actual operations of transferring data between the computer system and external devices</strong>. Device I/O encompasses the entire process of data exchange, including issuing I/O requests, device access, data transfer, and handling device status and interrupts. Device I/O operations are managed by the operating system, often initiated by user programs through system calls. The OS uses device drivers to carry out these I/O operations, controlling the hardware to perform data input or output. Device I/O is the fundamental mechanism for the computer system to interact with the external world.</p>
<p><strong>Key Distinction</strong>:</p>
<p><strong>Device drivers</strong> are the *software* components that enable communication with hardware, acting as translators between the OS and devices. <strong>Device I/O</strong> is the *process* of data transfer itself, the actual operations performed by the system to input or output data using hardware devices, facilitated by device drivers.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (d) (4 marks)</h3>
<div class="question-content">
<p>(d) Paul, a programmer with a certain software company was required to design an operating system that would use segmentation to manage memory. Outline four advantages for using this memory management technique.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Logical Address Space Structure</strong>: Segmentation allows for a <strong>logical view of memory</strong>, dividing the address space into logical units called segments (code, data, stack). This reflects the program's structure, making it easier to organize and manage memory logically. Programmers can work with logical segments, simplifying program design and modularity.</p>
<p data-number="2"><strong>Protection at Segment Level</strong>: Segmentation enables <strong>fine-grained memory protection at the segment level</strong>. Each segment can have its own protection attributes (read-only, read-write, execute-only), allowing the OS to enforce access control and prevent unauthorized access to specific segments. This enhances system security by providing segment-based protection boundaries.</p>
<p data-number="3"><strong>Sharing of Segments</strong>: Segmentation facilitates <strong>sharing of segments between processes</strong>. Segments, especially code segments for libraries or shared modules, can be shared among multiple processes while maintaining protection. This reduces memory duplication, improves memory efficiency, and enables efficient code sharing between programs.</p>
<p data-number="4"><strong>Dynamic Growth of Segments</strong>: Segments can <strong>grow or shrink dynamically</strong> as needed during program execution. This allows flexible memory allocation and efficient use of memory, as segments can adjust their size according to the program's data or code requirements, reducing wasted memory space compared to fixed-size partitions.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (a) (2 marks)</h3>
<div class="question-content">
<p>4. (a) Explain the term pipe as used in operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>A <strong>pipe</strong> in operating systems is a mechanism for <strong>inter-process communication (IPC)</strong> that allows <strong>unidirectional data flow</strong> between two or more processes. It acts as a <strong>communication channel</strong> where one process can write data into one end of the pipe, and another process can read that data from the other end. Pipes are typically used for communication between related processes, like parent and child processes, or processes in a pipeline of commands. They provide a simple and efficient way for processes to exchange data sequentially.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (b) (4 marks)</h3>
<div class="question-content">
<p>(b) Outline four factors that should be considered when selecting computer memory other than cost.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Speed (Access Time and Cycle Time)</strong>: <strong>Memory speed</strong> is a crucial factor, measured by <strong>access time</strong> (time to retrieve data) and <strong>cycle time</strong> (time between successive accesses). Faster memory reduces latency and improves system performance. Different memory types (e.g., DDR5, DDR4) offer varying speeds. The required speed depends on the application and system performance needs.</p>
<p data-number="2"><strong>Capacity (Size)</strong>: <strong>Memory capacity</strong>, measured in GB or TB, determines the amount of data and programs that can be held in memory simultaneously. Higher capacity allows for running more applications and handling larger datasets without relying on slower secondary storage (disk). The needed capacity depends on the workload and expected memory usage of applications.</p>
<p data-number="3"><strong>Latency</strong>: <strong>Memory latency</strong> is the delay between requesting data and the data becoming available. Lower latency improves system responsiveness, especially for applications that require frequent memory accesses. Memory latency affects overall CPU performance and application speed. Different memory technologies have different latency characteristics.</p>
<p data-number="4"><strong>Power Consumption and Energy Efficiency</strong>: <strong>Power consumption</strong> is an important factor, especially for portable devices and energy-efficient systems. Memory modules vary in their power requirements and energy efficiency. Lower power consumption reduces heat generation, extends battery life in laptops, and lowers operating costs in data centers. Energy efficiency is increasingly important for sustainable computing.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (c) (6 marks)</h3>
<div class="question-content">
<p>(c) Explain three approaches that could be used to manage deadlocks in an operating system.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Deadlock Prevention</strong>: <strong>Deadlock prevention</strong> aims to <strong>prevent deadlocks by negating one or more of the necessary conditions for deadlock</strong> to occur (Mutual Exclusion, Hold and Wait, No Preemption, Circular Wait). Techniques include: * <strong>Mutual Exclusion</strong>: Making resources shareable (not always possible). * <strong>Hold and Wait</strong>: Requiring processes to request all needed resources at once or not hold resources when requesting new ones. * <strong>No Preemption</strong>: Allowing preemption of resources from a process under certain conditions. * <strong>Circular Wait</strong>: Imposing a linear ordering of resource types and requiring processes to request resources in increasing order. Deadlock prevention is proactive but can lead to reduced resource utilization and system performance due to restrictions on resource allocation.</p>
<p data-number="2"><strong>Deadlock Avoidance</strong>: <strong>Deadlock avoidance</strong> allows the system to enter a potential deadlock state but <strong>makes decisions to avoid entering a deadlock</strong>. It requires the system to have <strong>a priori information</strong> about the maximum resource needs of each process. Algorithms like the <strong>Banker's Algorithm</strong> are used to dynamically check if granting a resource request will lead to a safe state (a state where all processes can complete without deadlock). Deadlock avoidance is less restrictive than prevention but requires advance knowledge and can also limit resource utilization to ensure safety.</p>
<p data-number="3"><strong>Deadlock Detection and Recovery</strong>: <strong>Deadlock detection and recovery</strong> allows deadlocks to occur but <strong>detects when a deadlock has happened and takes actions to recover</strong>. The system periodically checks for deadlocks using algorithms to detect cycles in the resource allocation graph. If a deadlock is detected, recovery strategies are employed, such as <strong>process termination</strong> (aborting one or more deadlocked processes) or <strong>resource preemption</strong> (forcibly taking resources from processes). Deadlock detection and recovery is reactive, allowing for higher resource utilization but incurring overhead for detection and recovery, and potentially causing process restarts and data loss during recovery.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (d) (i) (4 marks)</h3>
<div class="question-content">
<p>(d) Figure 1 shows a typical a process control block diagram in an operating system. Use it to answer the questions that follow.</p>
<p><img src="Screenshot_2025-03-12_at_13-27-13_2012n.pdf.png" alt="" width="519" height="526" /></p>
<img src="figure1_q4d.png" alt="Figure 1 Process Control Block Diagram" />
<p>(i) Identify each of the layers of the diagram labeled (i), (ii), (iii) and (iv).</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>Based on Figure 1, which represents a Process Control Block (PCB) diagram:</p>
<p><strong>(i) Process Identifier (PID) / Process Number</strong>: Label (i) points to the section for "Process number". This field is the <strong>unique identifier</strong> assigned to each process by the operating system. It is used to distinguish and manage different processes within the system.</p>
<p><strong>(ii) Program Counter (PC)</strong>: Label (ii) points to a section that would typically represent the <strong>Program Counter</strong>. The Program Counter stores the <strong>address of the next instruction</strong> to be executed by the process. It is crucial for process execution and context switching.</p>
<p><strong>(iii) Registers</strong>: Label (iii) likely indicates the section for <strong>CPU Registers</strong>. This area stores the <strong>current values of the CPU registers</strong> for the process. Registers hold temporary data and intermediate results that the process is actively using. Saving and restoring register values is a key part of context switching.</p>
<p><strong>(iv) Process State</strong>: Label (iv) points to "Process state". This field indicates the <strong>current state of the process</strong>, such as New, Ready, Running, Waiting, or Terminated. The process state is essential for process scheduling and management, reflecting the current activity and status of the process within the system.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (d) (ii) (4marks)</h3>
<div class="question-content">
<p>(d) Figure 1 shows a typical a process control block diagram in an operating system. Use it to answer the questions that follow.</p>
<p>(ii) Outline four elements of process control information in a process control block diagram.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Process State</strong>: The <strong>current state of the process</strong> (e.g., running, ready, waiting, new, terminated) is a critical element. It indicates the current activity of the process and is used by the scheduler to manage process execution.</p>
<p data-number="2"><strong>Program Counter (PC)</strong>: The <strong>program counter</strong>, as mentioned, stores the address of the next instruction to be executed. It is essential for resuming process execution after context switches or interruptions.</p>
<p data-number="3"><strong>CPU Registers</strong>: The <strong>contents of CPU registers</strong>, including general-purpose registers, stack pointer, and status registers, need to be saved in the PCB. These registers hold the process's working data and execution context and must be restored when the process resumes execution.</p>
<p data-number="4"><strong>Memory Management Information</strong>: The PCB contains <strong>memory management information</strong>, such as pointers to page tables or segment tables. This information is necessary for the operating system to manage the process's virtual memory space and translate virtual addresses to physical addresses during execution.</p>
</div>
</div>
</section>
<section class="question">
<h3>5. (a) (i) (2 marks)</h3>
<div class="question-content">
<p>5. (a) (i) Explain the term semaphore as used in operating system.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>A <strong>semaphore</strong> is a synchronization primitive used in operating systems for controlling access to <strong>shared resources</strong> and for process synchronization. It is an integer variable that, apart from initialization, is accessed only through two atomic operations: <strong>wait (P)</strong> and <strong>signal (V)</strong>. Semaphores help manage critical sections and prevent race conditions in concurrent systems by controlling the number of processes that can access a resource simultaneously.</p>
</div>
</div>
</section>
<section class="question">
<h3>5. (a) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Differentiate between fixed and dynamic memory partitioning.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Fixed Memory Partitioning</strong>:</p>
<p>In <strong>fixed memory partitioning</strong>, main memory is divided into a <strong>fixed number of partitions</strong> at system initialization. Each partition has a <strong>predetermined size</strong>, which is set at system startup and remains constant. Partitions can be of equal size (equal-sized partitioning) or varying sizes (unequal-sized partitioning). Each partition can hold only one process at a time. <strong>Advantages</strong>: Simple to implement and manage. <strong>Disadvantages</strong>: Internal fragmentation (if process size is smaller than partition size), limits degree of multiprogramming due to fixed number of partitions, and inefficient memory utilization if partition sizes are not well-matched to process sizes.</p>
<p><strong>Dynamic Memory Partitioning</strong>:</p>
<p>In <strong>dynamic memory partitioning</strong>, memory partitions are created <strong>dynamically at runtime</strong>, based on the actual memory requirements of processes. When a process needs to be loaded, the operating system allocates a partition of exactly the size needed by the process from the available free memory. Partitions are created and sized as needed, and they are not fixed beforehand. <strong>Advantages</strong>: Reduces internal fragmentation as partitions are tailored to process size, allows for more efficient memory utilization compared to fixed partitioning. <strong>Disadvantages</strong>: External fragmentation can occur over time as memory becomes fragmented into smaller, non-contiguous blocks, and memory management is more complex compared to fixed partitioning.</p>
<p><strong>Key Distinction</strong>:</p>
<p>The primary difference is in how partitions are created and sized. <strong>Fixed partitioning</strong> uses pre-defined, static partitions, while <strong>dynamic partitioning</strong> creates partitions dynamically based on process needs. Fixed partitioning is simpler but leads to internal fragmentation, while dynamic partitioning is more memory-efficient but can suffer from external fragmentation.</p>
</div>
</div>
</section>
<section class="question">
<h3>5. (b) (i) (2 marks)</h3>
<div class="question-content">
<p>Figure 2 shows a typical I/O communication technique. Use it to answer the questions that follow.</p>
<p><img src="Screenshot_2025-03-12_at_13-28-29_2012n.pdf.png" alt="" width="824" height="599" /></p>
<img src="figure2_q5b.png" alt="Figure 2 I/O Communication Technique Diagram" />
<p>(i) Identify the I/O communication technique exhibited in the diagram justifying your answer.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>The I/O communication technique exhibited in the diagram is <strong>Direct Memory Access (DMA)</strong>. This is identified by the presence of a "DMA Controller" component shown in the diagram, which is responsible for managing data transfer between the I/O subsystem and Main memory, bypassing the direct involvement of the CPU for each data word transfer.</p>
</div>
</div>
</section>
<section class="question">
<h3>5. (b) (ii) (4 marks)</h3>
<div class="question-content">
<p>Figure 2 shows a typical I/O communication technique. Use it to answer the questions that follow.</p>
<p>(ii) Outline the procedure used by the I/O communication technique identified in (i).</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>The procedure used by <strong>Direct Memory Access (DMA)</strong> communication technique is as follows:</p>
<p data-number="1"><strong>CPU Initiation</strong>: The CPU initiates the DMA transfer by programming the <strong>DMA Controller</strong>. This involves providing the DMA controller with information such as the <strong>source address</strong> (memory or I/O device), <strong>destination address</strong> (memory or I/O device), <strong>data count</strong> (number of bytes to transfer), and the <strong>direction of transfer</strong> (read or write).</p>
<p data-number="2"><strong>DMA Transfer Execution</strong>: Once programmed, the DMA controller takes over the data transfer. It <strong>directly transfers data</strong> between the I/O device and main memory via the <strong>System bus</strong>, without further CPU intervention for each byte or word transferred. The CPU is free to perform other tasks concurrently during this DMA transfer.</p>
<p data-number="3"><strong>Data Transfer and Memory Access</strong>: The DMA controller <strong>requests access to the system bus</strong> and main memory. It manages the data transfer process, handling addressing, bus arbitration, and data synchronization. Data is transferred in blocks or bursts for efficiency.</p>
<p data-number="4"><strong>Transfer Completion and Notification</strong>: After completing the data transfer, the DMA controller <strong>notifies the CPU</strong>, typically through an <strong>interrupt</strong>. This signals that the DMA operation is complete, and the CPU can then process the transferred data or initiate further I/O operations. The DMA controller relinquishes control of the bus after the transfer is done.</p>
</div>
</div>
</section>
<section class="question">
<h3>5. (c) (4 marks)</h3>
<div class="question-content">
<p>(c) Tom, an intern student was required to design I/O module for a certain operating system. Explain two objectives that he could consider.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Device Independence</strong>: One key objective is to achieve <strong>device independence</strong>. The I/O module should be designed to provide a <strong>uniform interface</strong> to the operating system and user programs, regardless of the specific characteristics of different I/O devices. This allows applications to perform I/O operations without needing to know the details of each device, making the system more portable and easier to maintain. Device drivers handle device-specific details, providing an abstraction layer.</p>
<p data-number="2"><strong>Efficiency and Performance</strong>: Another crucial objective is to ensure <strong>efficient and high-performance I/O operations</strong>. The I/O module should be designed to minimize overhead, maximize data transfer rates, and optimize resource utilization. Techniques like <strong>buffering, caching, and DMA</strong> should be considered to improve I/O performance and reduce CPU involvement in data transfer. Efficiency is essential for overall system responsiveness and throughput.</p>
</div>
</div>
</section>
<section class="question">
<h3>5. (d) (4 marks)</h3>
<div class="question-content">
<p>(d) Mark, a systems consultant recommended an I/O buffering add-on module to an operating system. Explain two conditions that could justify Mark's recommendation.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Speed Mismatch between CPU and I/O Devices</strong>: A condition justifying I/O buffering is a significant <strong>speed mismatch between the CPU and I/O devices</strong>. I/O devices, especially slower ones like hard disks or network interfaces, operate at speeds much lower than the CPU's processing speed. Buffering can <strong>bridge this speed gap</strong> by temporarily holding data being transferred between the CPU and I/O devices. This allows the CPU to continue processing without waiting for slow I/O operations to complete, improving overall system throughput and CPU utilization.</p>
<p data-number="2"><strong>Data Transfer Size Discrepancies</strong>: Another condition is when there are <strong>discrepancies in data transfer sizes</strong> between the CPU/memory and I/O devices. For example, the CPU may process data in larger blocks, while I/O devices may transfer data in smaller units or variable sizes. Buffering provides a <strong>temporary storage area to accumulate or decompose data</strong>, enabling efficient data transfer between components with different data handling granularities. Buffering helps to adapt data flow to match the requirements of both the CPU/memory system and the I/O devices, optimizing data transfer efficiency and reducing overhead.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (a) (i) (2 marks)</h3>
<div class="question-content">
<p>6. (a) Explain each of the following terms as used in I/O devices:</p>
<p>(i) disk cache:</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Disk Cache</strong> is a <strong>portion of RAM</strong> (Random Access Memory) that is used as a <strong>cache memory for disk I/O operations</strong>. It stores frequently accessed data blocks from the hard disk to speed up subsequent accesses. When the system needs to read data from the disk, it first checks the disk cache. If the data is found in the cache (cache hit), it is retrieved from the faster RAM cache instead of the slower disk, significantly reducing access time and improving I/O performance.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (a) (ii) (2 marks)</h3>
<div class="question-content">
<p>Explain each of the following terms as used in I/O devices:</p>
<p>(ii) cache manager.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Cache Manager</strong> is the <strong>software component</strong> within the operating system that <strong>manages the disk cache</strong>. It is responsible for implementing cache policies, such as deciding which data blocks to store in the cache, when to retrieve data from disk into the cache, and which blocks to replace when the cache is full (cache replacement policies). The cache manager aims to optimize cache hit rate and minimize cache misses, thereby maximizing the performance benefits of disk caching.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (b) (4 marks)</h3>
<div class="question-content">
<p>(b) A group of Module II students were carrying out assignment on categories of I/O devices. Explain two categories they are likely to have mentioned in the report.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Storage Devices</strong>: <strong>Storage devices</strong> form a major category of I/O devices, used for <strong>long-term data storage</strong>. These include <strong>Hard Disk Drives (HDDs) and Solid State Drives (SSDs)</strong>. HDDs use magnetic platters for storage and are characterized by larger capacities and lower cost per GB, but have slower access times and higher latency. SSDs use flash memory for storage, offering much faster access times, lower latency, and better durability, but are typically more expensive per GB and may have lower capacities compared to HDDs. Storage devices are crucial for persistent data storage and file systems.</p>
<p data-number="2"><strong>Human-Interface Devices (HIDs)</strong>: <strong>Human-Interface Devices (HIDs)</strong> constitute another significant category, enabling <strong>human-computer interaction</strong>. These include <strong>keyboards, mice, monitors, and touchscreens</strong>. Keyboards and mice are input devices for user commands and data entry. Monitors and touchscreens are output devices for displaying visual information and, in the case of touchscreens, also for input. HIDs facilitate user interaction with the computer system, enabling input, output, and control.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (c) (4 marks)</h3>
<div class="question-content">
<p>(c) Ann, an intern student was required to list elements in a file descriptor in her company's file system. Outline four elements that she could have listed.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>File Permissions/Access Rights</strong>: <strong>File permissions</strong> define who can access the file and what operations they are allowed to perform (e.g., read, write, execute). Permissions typically include settings for the file owner, group, and others, controlling access for different categories of users.</p>
<p data-number="2"><strong>File Size</strong>: <strong>File size</strong> indicates the current size of the file in bytes or blocks. This attribute is essential for storage management, disk space allocation, and for applications to know the amount of data they are dealing with.</p>
<p data-number="3"><strong>File Owner and Group IDs</strong>: <strong>Owner ID and Group ID</strong> identify the user and group associated with the file. These attributes are crucial for implementing file ownership and access control, determining who has administrative rights over the file and which group it belongs to.</p>
<p data-number="4"><strong>File Data Block Locations</strong>: <strong>Pointers to data blocks</strong> or extent information indicating where the actual file data is stored on disk. This is critical for the file system to locate and retrieve the file's content from physical storage. The method of tracking data block locations varies depending on the file system (e.g., inodes, file allocation tables).</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (d) (i) (2 marks)</h3>
<div class="question-content">
<p>(d) For each of the following cases, explain the most appropriate disk scheduling algorithm for the following scenarios:</p>
<p>(i) fair clustered requests;</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>For <strong>fair clustered requests</strong>, the most appropriate disk scheduling algorithm is <strong>SCAN (Elevator)</strong> or <strong>C-SCAN (Circular SCAN)</strong>. These algorithms provide fairness by servicing requests in a sweep across the disk, preventing starvation and ensuring that all parts of the disk get serviced. SCAN and C-SCAN are effective in handling clustered requests as they efficiently service requests in the direction of head movement, reducing seek times and providing a balance between performance and fairness.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (d) (ii) (2 marks)</h3>
<div class="question-content">
<p>(d) For each of the following cases, explain the most appropriate disk scheduling algorithm for the following scenarios:</p>
<p>(ii) minimizes seek time;</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>For the scenario where the goal is to <strong>minimize seek time</strong>, the most appropriate disk scheduling algorithm is <strong>Shortest Seek Time First (SSTF)</strong>. SSTF algorithm selects the disk request that requires the <strong>minimum seek distance</strong> from the current head position. By always choosing the nearest request, SSTF minimizes the overall head movement and, consequently, the average seek time, leading to improved disk throughput and reduced response times.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (d) (iii) (2 marks)</h3>
<div class="question-content">
<p>(d) For each of the following cases, explain the most appropriate disk scheduling algorithm for the following scenarios:</p>
<p>(iii) services requests in track order based on the movement of the head;</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>For servicing requests in track order based on head movement, the most appropriate disk scheduling algorithm is <strong>SCAN (Elevator)</strong> or <strong>C-SCAN (Circular SCAN)</strong>. These algorithms move the disk head in one direction, servicing all requests encountered in that direction, and then reverse or reposition the head to continue servicing in the other direction (SCAN) or from the beginning (C-SCAN). They naturally service requests in track order along the path of head movement.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (d) (iv) (2 marks)</h3>
<div class="question-content">
<p>(d) For each of the following cases, explain the most appropriate disk scheduling algorithm for the following scenarios:</p>
<p>(iv) changes directions when read/write head reaches the last request in the current direction.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>For the scenario of changing directions when the read/write head reaches the last request in the current direction, the most appropriate disk scheduling algorithm is <strong>SCAN (Elevator)</strong>. The SCAN algorithm specifically operates by moving the head in one direction, servicing requests, and then reversing direction when it reaches the last request in that direction (or the end of the disk), resembling the movement of an elevator servicing floors.</p>
</div>
</div>
</section>
<section class="question">
<h3>7. (a) (4 marks)</h3>
<div class="question-content">
<p>7. (a) Outline four properties of a file system as used in operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Data Persistence</strong>: A file system provides <strong>persistent storage</strong> for data, meaning data is stored in files on non-volatile storage devices (like hard disks or SSDs) and remains available even after the system is powered off. This property ensures that data is not lost when the system shuts down, enabling long-term data retention.</p>
<p data-number="2"><strong>Organization and Hierarchical Structure</strong>: File systems organize files into a <strong>hierarchical directory structure</strong> (tree-like structure). This allows users to group related files into directories (folders), creating a logical and organized file system. Hierarchical structure simplifies file management, navigation, and organization, making it easier to locate and access files.</p>
<p data-number="3"><strong>Naming and Identification</strong>: A file system provides a <strong>naming scheme for files and directories</strong>, allowing users to identify and access files using names. File names are typically human-readable and follow specific naming conventions. The file system manages the mapping between file names and their physical storage locations, enabling users to refer to files by name rather than physical addresses.</p>
<p data-number="4"><strong>Access Control and Security</strong>: File systems incorporate <strong>access control mechanisms</strong> to regulate who can access files and directories and what operations they can perform (read, write, execute). Permissions and access rights are used to protect files from unauthorized access, modification, or deletion, ensuring data security and privacy. File system security mechanisms control and manage access based on user and group identities.</p>
</div>
</div>
</section>
<section class="question">
<h3>7. (b) (4 marks)</h3>
<div class="question-content">
<p>(b) Differentiate between cache memory and main memory as used in computer systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Cache Memory</strong>:</p>
<p><strong>Cache memory</strong> is a <strong>small, fast memory</strong> that is located closer to the CPU than main memory. It is used to store <strong>frequently accessed data and instructions</strong> to speed up access times. Cache memory operates on the principles of locality (temporal and spatial locality), predicting that data recently accessed or near recently accessed data is likely to be needed again soon. There are typically multiple levels of cache (L1, L2, L3), with L1 being the fastest and smallest, closest to the CPU. Cache is <strong>expensive and volatile</strong>.</p>
<p><strong>Main Memory (RAM)</strong>:</p>
<p><strong>Main memory</strong>, or <strong>RAM (Random Access Memory)</strong>, is the <strong>primary memory</strong> of the computer system. It is larger and slower than cache memory but faster than secondary storage (like hard drives). RAM is used to store the <strong>currently running programs and data</strong> that the CPU is actively using. RAM is also <strong>volatile</strong>, meaning it loses its data when power is turned off. It is less expensive per byte compared to cache memory and provides a larger capacity for working data and programs.</p>
<p><strong>Key Distinction</strong>:</p>
<p>The main differences lie in <strong>speed, size, cost, and purpose</strong>. <strong>Cache memory</strong> is smaller, faster, more expensive, and used for temporary storage of frequently accessed data to speed up CPU access. <strong>Main memory (RAM)</strong> is larger, slower, less expensive, and serves as the primary working memory for running programs and data.</p>
</div>
</div>
</section>
<section class="question">
<h3>7. (c) (6 marks)</h3>
<div class="question-content">
<p>(c) XWZ Software Company Ltd. intends to design an operating system that would ensure efficient memory placements. Explain three types of placement algorithms it could design.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>First-Fit</strong>: The <strong>First-Fit algorithm</strong> is a memory placement technique that allocates the <strong>first available memory partition</strong> (or hole) that is large enough to accommodate the process. The operating system scans through the list of free memory partitions in order and selects the first one that satisfies the memory requirement. <strong>Advantage</strong>: Simple and fast to implement as it only requires a linear scan of free partitions. <strong>Disadvantage</strong>: Can lead to fragmentation and may not efficiently utilize memory space, potentially leaving larger free blocks unused at the end of memory.</p>
<p data-number="2"><strong>Best-Fit</strong>: The <strong>Best-Fit algorithm</strong> allocates the <strong>smallest available memory partition</strong> that is large enough to hold the process. The operating system searches the entire list of free partitions and chooses the one that is closest in size to the process's requirement. <strong>Advantage</strong>: Tends to minimize memory wastage and external fragmentation compared to first-fit by using up smaller free blocks. <strong>Disadvantage</strong>: Can be slower than first-fit due to the need to search the entire list to find the best fit and may lead to many small, unusable free blocks remaining.</p>
<p data-number="3"><strong>Worst-Fit</strong>: The <strong>Worst-Fit algorithm</strong> allocates the <strong>largest available memory partition</strong> to the process. The operating system searches through all free partitions and selects the largest one. <strong>Advantage</strong>: Aims to leave larger free blocks after allocation, potentially accommodating larger future processes. <strong>Disadvantage</strong>: Can quickly deplete larger free blocks, leading to fragmentation and potentially making it difficult to allocate memory for large processes in the long run, and may result in larger internal fragmentation for smaller processes allocated to very large partitions.</p>
</div>
</div>
</section>
<section class="question">
<h3>7. (d) (4 marks)</h3>
<div class="question-content">
<p>(d) Figure 2 shows a memory management technique used in systems. Use to answer the questions that follow.</p>
<p><img src="Screenshot_2025-03-12_at_13-30-13_2012n.pdf.png" alt="" width="785" height="665" /></p>
<img src="figure2_q7d.png" alt="Figure 2 Memory Management Technique Diagram" />
<p>(i) Describe the memory management technique represented in the figure.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>The memory management technique represented in Figure 2 is <strong>Paging</strong>. This is indicated by the diagram showing:</p>
<p>- <strong>Logical Address</strong> being divided into two parts: <strong>p (page number)</strong> and <strong>d (page offset)</strong>.</p>
<p>- A <strong>Page Table</strong>, which is used to map page numbers to frame numbers.</p>
<p>- <strong>Physical Address</strong> being constructed from the <strong>frame number (f)</strong> obtained from the page table and the <strong>page offset (d)</strong>.</p>
<p>- The process of address translation where a logical address is converted into a physical address using the page table to locate the physical frame in <strong>physical memory</strong>.</p>
<p>These elements are characteristic of paged memory management, where virtual memory is divided into fixed-size pages and physical memory into frames, and a page table manages the mapping between them.</p>
</div>
</div>
</section>
<section class="question">
<h3>7. (d) (ii) (2 marks)</h3>
<div class="question-content">
<p>Figure 2 shows a memory management technique used in systems. Use to answer the questions that follow.</p>
<p>(ii) Outline two advantages of the technique described in (i).</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Eliminates External Fragmentation</strong>: <strong>Paging eliminates external fragmentation</strong>. Because both logical and physical memory are divided into fixed-size pages and frames, any available frame can be used to load a page of a process. This prevents the situation where there is enough total free memory but it is non-contiguous and cannot be used to load a process, which is a problem in segmentation and dynamic partitioning.</p>
<p data-number="2"><strong>Supports Virtual Memory</strong>: Paging is a fundamental technique for implementing <strong>virtual memory</strong>. It allows processes to have a logical address space larger than the physical memory. Only the currently needed pages of a process need to be in RAM, while the rest can reside on secondary storage (disk). This enables running larger programs than physical memory size and increases the degree of multiprogramming.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (a) (i) (3 marks)</h3>
<div class="question-content">
<p>8. (a) (i) Outline three components of processor's I/O instruction in a programmed I/O communication technique.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Opcode (Operation Code)</strong>: The <strong>opcode</strong> specifies the <strong>type of I/O operation</strong> to be performed. It indicates whether the instruction is for input (read from device) or output (write to device), and potentially other control functions. The opcode tells the processor what action to take concerning I/O.</p>
<p data-number="2"><strong>Device Address or Port Number</strong>: The I/O instruction must include the <strong>address or port number</strong> of the specific <strong>I/O device</strong> that the operation is intended for. This address uniquely identifies the target device (e.g., a specific peripheral controller or port). The device address ensures that the instruction is directed to the correct I/O device.</p>
<p data-number="3"><strong>Data or Memory Address</strong>: The I/O instruction typically needs to specify a <strong>data operand or a memory address</strong>. For output operations, this may be the <strong>data to be written</strong> to the device. For input operations, this may be a <strong>memory address where the data read from the device should be stored</strong>. This component defines the data involved in the I/O transfer or the memory location for data exchange.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (a) (ii) (2 marks)</h3>
<div class="question-content">
<p>(ii) With the aid of a diagram in each case, describe the following parts of a disk:</p>
<p>I. sector;</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>I. Sector</strong>:</p>
<p>A <strong>sector</strong> is the <strong>smallest physical storage unit</strong> on a disk. It is a subdivision of a track and is used to store a fixed amount of data, typically 512 bytes or 4KB. Sectors are the fundamental units for disk read and write operations. Each track on a disk is divided into multiple sectors.</p>
<p><strong>Diagram of Sector:</strong></p>
<pre>                       Track
                    +-----------------------+
                    | Sector 1 | Sector 2 | Sector 3 | ... | Sector N |
                    +-----------------------+
                    </pre>
<p><strong>Description</strong>: Sectors are pie-shaped segments within a track, each storing a fixed block of data and having a sector ID for addressing.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (a) (ii) (2 marks)</h3>
<div class="question-content">
<p>(ii) With the aid of a diagram in each case, describe the following parts of a disk:</p>
<p>II. track.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>II. Track</strong>:</p>
<p>A <strong>track</strong> is a <strong>concentric circular path</strong> on the surface of a disk platter where data is recorded. Tracks are arranged in concentric rings around the center of the platter. Data is written and read sequentially along a track. A disk platter contains many tracks, and tracks are further divided into sectors.</p>
<p><strong>Diagram of Track:</strong></p>
<pre>                         Disk Platter
                       +-------------+
                     /               \
                    /  Track 0 (outer)  \
                   |   -------------   |
                   |  Track 1          |
                   |   -------------   |
                   |      ...          |
                   |   -------------   |
                   \  Track N (inner)  /
                    \               /
                       +-------------+
                    </pre>
<p><strong>Description</strong>: Tracks are concentric rings on the platter surface, each track storing data sequentially and being divided into sectors.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (b) (5 marks)</h3>
<div class="question-content">
<p>(b) Maurine, an intern system analyst with Ujuzi Company Ltd. was required to establish a file organization method for her Company's database system. Outline five criteria she could consider when selecting the file organization method.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Access Type and Frequency</strong>: Maurine should consider the <strong>primary access type</strong> for the database. Is it mainly <strong>sequential access</strong> (e.g., batch processing, reports) or <strong>random access</strong> (e.g., transaction processing, queries)? Also, consider the <strong>frequency of access</strong> for different types of operations (read-heavy vs. write-heavy). The chosen file organization should efficiently support the dominant access patterns and frequencies.</p>
<p data-number="2"><strong>Data Volatility and Update Requirements</strong>: Consider how frequently the database data will be <strong>updated or modified</strong>. If updates are frequent, the file organization should efficiently support record insertion, deletion, and modification without significant performance overhead. Highly volatile data may favor organizations that handle updates efficiently. For relatively static data, update efficiency might be less critical.</p>
<p data-number="3"><strong>Storage Efficiency and Overhead</strong>: Evaluate the <strong>storage efficiency</strong> of different file organizations. Some methods may lead to more wasted space (e.g., internal or external fragmentation), while others are more space-efficient. Also, consider the <strong>overhead</strong> associated with metadata (indexes, headers) required by the file organization. Storage efficiency and overhead impact the overall disk space utilization and storage costs for the database.</p>
<p data-number="4"><strong>Search and Retrieval Performance</strong>: Assess the <strong>performance of search and retrieval operations</strong>. The file organization should enable efficient retrieval of specific records based on search criteria (keys). Consider the speed of record lookup, query processing, and data retrieval for common database queries. Different file organizations offer varying search efficiencies, impacting query response times.</p>
<p data-number="5"><strong>Implementation Complexity and Maintenance</strong>: Consider the <strong>complexity of implementing and maintaining</strong> the file organization method. Some methods are simpler to implement and manage, while others are more complex, requiring specialized skills and tools. Balance the performance benefits with the complexity of implementation and long-term maintenance overhead. Simpler methods may be preferred if development time and maintenance are key concerns.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (c) (4 marks)</h3>
<div class="question-content">
<p>(c) Jua-kali Company Ltd. is experiencing privacy issues with confidential information in their system. Explain two logical security measures it could use to mitigate the problem.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Access Control Mechanisms</strong>: Implement robust <strong>access control mechanisms</strong>, such as <strong>Access Control Lists (ACLs) or Role-Based Access Control (RBAC)</strong>. These mechanisms restrict access to confidential information based on user identity and roles. Configure permissions to ensure that only authorized personnel can access, modify, or delete sensitive data. Access control helps prevent unauthorized users from gaining access to confidential information, mitigating privacy issues.</p>
<p data-number="2"><strong>Data Encryption</strong>: Employ <strong>data encryption</strong> to protect confidential information both <strong>in transit and at rest</strong>. Encrypt sensitive data files and databases using strong encryption algorithms. Encryption ensures that even if unauthorized individuals gain access to the data, it remains unreadable without the decryption key. Use encryption for data stored on servers, backups, and during transmission over networks to prevent data breaches and protect privacy.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (d) (4 marks)</h3>
<div class="question-content">
<p>(d) An operating system has been designed to use memory overlay. Explain two disadvantages of this technique.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Programming Complexity and Programmer Burden</strong>: <strong>Overlay programming</strong> is <strong>complex and places a significant burden on programmers</strong>. Developers must manually divide programs into overlays and carefully manage the loading and unloading of overlays during execution. This requires detailed knowledge of memory usage and program structure, making program development and maintenance more difficult and error-prone. Programmers need to handle overlay management explicitly, increasing development time and complexity.</p>
<p data-number="2"><strong>Reduced Performance and Overhead</strong>: <strong>Overlaying can lead to reduced performance and introduces overhead</strong>. The process of swapping overlays between main memory and secondary storage (disk) is <strong>time-consuming</strong>. Frequent overlay swapping, especially if overlays are not designed efficiently, can result in significant disk I/O overhead and slow down program execution. The overhead of overlay management and the latency of disk access can degrade overall system performance, particularly for programs with complex overlay structures or frequent overlay switching.</p>
</div>
</div>
</section>
</main></p>
<p></p>
<p></p>
<footer>© 2023 [Your University/College Name]</footer></div>
</div>
</div>
</article>
</section>
</div>
<div id='bottomPagination'>
<nav class="pagination noprt">
<a href="july_2013.html" class="prev"><span><span>&laquo; </span>Previous</span></a> <span class="sep">| </span><a href="july_2012.html" class="next"><span>Next<span> &raquo;</span></span></a>
</nav>
</div>
</div>
<script type="text/javascript" src="_intef_js.js"></script></body></html>