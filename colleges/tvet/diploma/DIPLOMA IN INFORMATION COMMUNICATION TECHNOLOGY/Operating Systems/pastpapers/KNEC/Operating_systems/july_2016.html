<!doctype html>
<html lang="en">
<head>
<link rel="stylesheet" type="text/css" href="base.css" />
<link rel="stylesheet" type="text/css" href="content.css" />
<link rel="stylesheet" type="text/css" href="nav.css" />
<meta http-equiv="content-type" content="text/html;  charset=utf-8" />
<title>July 2016 </title>
<link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<meta name="generator" content="eXeLearning 2.9 - exelearning.net" />
<!--[if lt IE 9]><script type="text/javascript" src="exe_html5.js"></script><![endif]-->
<script type="text/javascript" src="exe_jquery.js"></script>
<script type="text/javascript" src="common_i18n.js"></script>
<script type="text/javascript" src="common.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
</head>
<body class="exe-web-site" id="exe-node-9"><script type="text/javascript">document.body.className+=" js"</script>
<div id="content">
<p id="skipNav"><a href="#main" class="sr-av">Skip navigation</a></p>
<section id="emptyHeader"></section>
<nav id="siteNav">
<ul>
   <li><a href="index.html" class="daddy main-node">Home</a></li>
   <li><a href="july_2023.html" class="no-ch">July 2023</a></li>
   <li><a href="november_2021.html" class="no-ch">November 2021</a></li>
   <li><a href="july_2021.html" class="no-ch">July 2021</a></li>
   <li><a href="july_2019.html" class="no-ch">July 2019</a></li>
   <li><a href="november_2018.html" class="no-ch">November 2018</a></li>
   <li><a href="november_2017.html" class="no-ch">November 2017</a></li>
   <li><a href="july_2017.html" class="no-ch">July 2017</a></li>
   <li><a href="november_2016.html" class="no-ch">November 2016</a></li>
   <li id="active"><a href="july_2016.html" class="active no-ch">July 2016</a></li>
   <li><a href="november_2015.html" class="no-ch">November 2015</a></li>
   <li><a href="july_2015.html" class="no-ch">July 2015</a></li>
   <li><a href="novemeber_2014.html" class="no-ch">Novemeber 2014</a></li>
   <li><a href="july_2014.html" class="no-ch">July 2014</a></li>
   <li><a href="november_2013.html" class="no-ch">November 2013</a></li>
   <li><a href="july_2013.html" class="no-ch">July 2013</a></li>
   <li><a href="november_2012.html" class="no-ch">November 2012</a></li>
   <li><a href="july_2012.html" class="no-ch">July 2012</a></li>
   <li><a href="july_2011.html" class="no-ch">July 2011</a></li>
</ul>
</nav>
<div id='topPagination'>
<nav class="pagination noprt">
<a href="november_2016.html" class="prev"><span><span>&laquo; </span>Previous</span></a> <span class="sep">| </span><a href="november_2015.html" class="next"><span>Next<span> &raquo;</span></span></a>
</nav>
</div>
<div id="main-wrapper">
<section id="main">
<header id="nodeDecoration"><h1 id="nodeTitle">July 2016</h1></header>
<article class="iDevice_wrapper textIdevice" id="id9">
<div class="iDevice emphasis0" >
<div id="ta9_131_2" class="block iDevice_content">
<div class="exe-text"><p></p>
<style>
        /* Modern CSS Reset */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        /* Base Styles */
        body {
            font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;
            line-height: 1.6;
            color: #2d3748;
            background-color: #f7fafc;
            margin: 0;
            padding: 0;
        }

        /* Header Styles */
        header {
            background: linear-gradient(135deg, #1a365d 0%, #2c5282 100%);
            color: white;
            padding: 2rem;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        header h1 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
            font-weight: 600;
        }

        .exam-details {
            background: rgba(255, 255, 255, 0.1);
            padding: 1rem;
            border-radius: 8px;
            display: inline-block;
            margin-top: 1rem;
        }

        .exam-details p {
            margin: 0.5rem 0;
            font-size: 1.1rem;
        }

        /* Main Content */
        main {
            max-width: 1200px;
            margin: 2rem auto;
            padding: 0 1.5rem;
        }

        /* Passage Styles */
        .passage {
            background: #edf2f7;
            border-radius: 12px;
            margin-bottom: 2rem;
            padding: 1.5rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
        }

        .passage h2 {
            color: #2d3748;
            margin-bottom: 1rem;
            font-size: 1.5rem;
            border-bottom: 2px solid #cbd5e0;
            padding-bottom: 0.5rem;
        }

        .passage-content {
            font-size: 1.1rem;
            color: #4a5568;
            line-height: 1.8;
        }

        .passage-content p {
            margin-bottom: 1rem;
        }

        /* Question Styles */
        .question {
            background: white;
            border-radius: 12px;
            margin-bottom: 2rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
            overflow: hidden;
        }

        .question h3 {
            background: #4a5568;
            color: white;
            padding: 1rem 1.5rem;
            font-size: 1.25rem;
            margin: 0;
            border-bottom: 3px solid #2d3748;
        }

        .question-content {
            padding: 1.5rem;
            background: #fff;
            border-bottom: 2px solid #edf2f7;
        }

        .question-content p {
            font-size: 1.1rem;
            color: #2d3748;
        }

        /* Answer Styles */
        .answer-section {
            background: #f8fafc;
            border-top: 2px solid #e2e8f0;
        }

        .answer-section h4 {
            padding: 1rem 1.5rem;
            color: #2d3748;
            font-size: 1.2rem;
            background: #edf2f7;
            margin: 0;
        }

        .answer-content {
            padding: 1.5rem;
            color: #4a5568;
        }

        .answer-content p {
            margin-bottom: 1rem;
            line-height: 1.8;
        }

        /* Bold Answers */
        .answer-content strong, .answer-content b {
            color: #2d3748;
            font-weight: 700;
        }

        /* Numbered Lists in Answers */
        .answer-content p[data-number]:before {
            content: attr(data-number) ".";
            font-weight: 600;
            margin-right: 0.5rem;
            color: #4a5568;
        }

        /* Table Styles */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
            overflow: hidden;
            border-radius: 8px;
        }

        thead {
            background-color: #4a5568;
            color: white;
        }

        th {
            text-align: left;
            padding: 0.75rem 1rem;
            font-weight: 600;
            border-bottom: 2px solid #2d3748;
        }

        td {
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            background-color: white;
        }

        tr:last-child td {
            border-bottom: none;
        }

        tr:nth-child(even) td {
            background-color: #f8fafc;
        }

        /* Footer Styles */
        footer {
            background: #2d3748;
            color: white;
            text-align: center;
            padding: 1.5rem;
            margin-top: 3rem;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            header h1 {
                font-size: 2rem;
            }

            main {
                padding: 0 1rem;
            }

            .passage h2 {
                font-size: 1.3rem;
            }

            .passage-content p {
                font-size: 1rem;
            }

            .question {
                margin-bottom: 1.5rem;
            }

            .question h3 {
                font-size: 1.1rem;
            }

            .question-content p,
            .answer-content p {
                font-size: 1rem;
            }
            
            table, thead, tbody, th, td, tr {
                display: block;
            }
            
            thead tr {
                position: absolute;
                top: -9999px;
                left: -9999px;
            }
            
            tr {
                border: 1px solid #e2e8f0;
                margin-bottom: 1rem;
                border-radius: 8px;
                overflow: hidden;
            }
            
            td {
                border: none;
                position: relative;
                padding-left: 50%;
                text-align: left;
                border-bottom: 1px solid #e2e8f0;
            }
            
            td:before {
                position: absolute;
                top: 0.75rem;
                left: 1rem;
                width: 45%;
                padding-right: 10px;
                white-space: nowrap;
                font-weight: 600;
                content: attr(data-label);
            }
            
            td:last-child {
                border-bottom: 0;
            }
        }

        /* Print Styles */
        @media print {
            body {
                background: white;
            }

            .passage,
            .question {
                break-inside: avoid;
                box-shadow: none;
                border: 1px solid #edf2f7;
            }

            header {
                background: white;
                color: black;
                padding: 1rem;
            }

            .exam-details {
                border: 1px solid #edf2f7;
            }
            
            table {
                break-inside: auto;
            }
            
            tr {
                break-inside: avoid;
                break-after: auto;
            }
        }
    </style>
<header>
<h1>OPERATING SYSTEMS</h1>
<div class="exam-details">
<p>Exam Code: 2920/105</p>
<p>Duration: 3 hours</p>
<p>Period: July 2016</p>
</div>
</header>
<p></p>
<p></p>
<p><main>
<section class="question">
<h3>1. (a) (2 marks)</h3>
<div class="question-content">
<p>(a) Explain the term interrupt as used in operating system.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>An <strong>interrupt</strong> is a <strong>signal</strong> generated by hardware or software to <strong>indicate an event that needs immediate attention</strong> from the operating system. It causes the CPU to <strong>suspend its current execution</strong>, save its state, and transfer control to an interrupt handler routine to deal with the event. After handling the interrupt, the CPU typically resumes the interrupted execution.</p>
</div>
</div>
</section>
<section class="question">
<h3>1. (b) (i) (2 marks)</h3>
<div class="question-content">
<p>(b) (i) Describe the term swapping as used in memory management.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Swapping</strong>:</p>
<p><strong>Swapping</strong> is a memory management technique where processes are <strong>moved between main memory (RAM) and secondary storage (disk)</strong> to allow more processes to run than can fit in memory at once. When memory is full, processes that are not currently active are swapped out to disk to free up space, and when they need to run again, they are swapped back into memory. Swapping is used to increase the degree of multiprogramming.</p>
</div>
</div>
</section>
<section class="question">
<h3>1. (b) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Outline four types of computer registers.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Program Counter (PC)</strong>: The <strong>Program Counter (PC)</strong> is a register that <strong>holds the address of the next instruction to be executed</strong>. It is incremented after each instruction is fetched, allowing the CPU to execute instructions in sequence. The PC is crucial for controlling the flow of execution in a program.</p>
<p data-number="2"><strong>Accumulator</strong>: The <strong>Accumulator</strong> is a register used for <strong>intermediate arithmetic and logical results</strong>. In older architectures, it was often the primary operand and destination for arithmetic operations. Modern CPUs may have multiple general-purpose registers, but the accumulator concept is still relevant for understanding CPU operations.</p>
<p data-number="3"><strong>Memory Address Register (MAR)</strong>: The <strong>Memory Address Register (MAR)</strong> holds the <strong>memory address to be accessed</strong> (read or write). When the CPU needs to access a location in memory, it loads the address into the MAR. The MAR is connected to the address bus and is essential for memory access operations.</p>
<p data-number="4"><strong>Memory Data Register (MDR)</strong>: The <strong>Memory Data Register (MDR)</strong>, also known as Memory Buffer Register (MBR), <strong>holds the data being transferred to or from memory</strong>. When reading from memory, data fetched from the memory location specified by the MAR is loaded into the MDR. When writing to memory, the data to be written is placed in the MDR and then transferred to the memory location specified by the MAR.</p>
</div>
</div>
</section>
<section class="question">
<h3>1. (c) (6 marks)</h3>
<div class="question-content">
<p>(c) Explain three roles of process control block in operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Process State Management</strong>: The <strong>Process Control Block (PCB)</strong> is crucial for <strong>managing the state of a process</strong>. It stores information about the current state of the process (e.g., running, ready, blocked), allowing the OS to track the execution status of each process. When a context switch occurs, the OS saves the current state of the running process in its PCB and restores the state of the next process from its PCB. This enables the OS to suspend and resume processes seamlessly, maintaining the execution context.</p>
<p data-number="2"><strong>Process Identification and Scheduling</strong>: The PCB serves as a <strong>unique identifier for each process</strong>. It contains the process ID (PID) and other identifiers that distinguish one process from another. The PCB also includes scheduling information, such as process priority, scheduling queue pointers, and CPU usage statistics. This scheduling information is used by the OS scheduler to make decisions about which process to run next and to implement scheduling policies (e.g., priority, round robin, etc.).</p>
<p data-number="3"><strong>Resource Management and Accounting</strong>: The PCB is used for <strong>managing and accounting the resources allocated to a process</strong>. It stores information about allocated memory, open files, I/O devices, and other resources used by the process. The OS uses the PCB to track resource ownership and usage, enforce resource limits, and deallocate resources when the process terminates. Resource accounting information in the PCB can also be used for performance monitoring and system administration.</p>
</div>
</div>
</section>
<section class="question">
<h3>1. (d) (i) (2 marks)</h3>
<div class="question-content">
<p>(d) (i) Outline two objectives for designing an operating system.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>User Convenience and Efficiency</strong>: One primary objective is to design an OS that is <strong>convenient and efficient for users</strong>. This includes providing a user-friendly interface, making the system easy to use and navigate, and ensuring good performance and responsiveness for user applications. The OS should aim to simplify user tasks and enhance productivity.</p>
<p data-number="2"><strong>Resource Management and Optimization</strong>: Another key objective is <strong>efficient resource management and optimization</strong>. The OS should manage system resources (CPU, memory, I/O devices) effectively to maximize utilization, throughput, and fairness. This involves implementing efficient scheduling algorithms, memory management techniques, and I/O management strategies to ensure optimal system performance and resource utilization.</p>
</div>
</div>
</section>
<section class="question">
<h3>1. (d) (4 marks)</h3>
<div class="question-content">
<p>(ii) Most processors support at least two modes of process execution. Explain two modes that are likely to be supported.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Kernel Mode (System Mode or Privileged Mode)</strong>: <strong>Kernel mode</strong> is a <strong>privileged execution mode</strong> in which the operating system kernel runs. In kernel mode, the CPU has unrestricted access to system hardware and memory. The kernel can execute any instruction, including privileged instructions, and can directly access memory and I/O devices. Kernel mode is essential for performing critical system operations, managing hardware, and enforcing security. It is typically reserved for OS kernel code to protect system integrity.</p>
<p data-number="2"><strong>User Mode (Non-privileged Mode)</strong>: <strong>User mode</strong> is a <strong>non-privileged execution mode</strong> in which user applications run. In user mode, the CPU has restricted access to system resources. User-mode processes cannot directly execute privileged instructions or access kernel memory or hardware. They must rely on system calls to request services from the kernel. User mode provides protection and security by isolating user applications from direct hardware access and preventing them from interfering with the OS or other processes. Most application code runs in user mode.</p>
<p><strong>Key Difference:</strong> Kernel mode is privileged, with full hardware access for the OS kernel. User mode is non-privileged, with restricted access for user applications, enhancing system security and stability.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (a) (i) (2 marks)</h3>
<div class="question-content">
<p>2. (a) Explain each of the following terms as used in operating system:</p>
<p>(i) time slice;</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Time Slice</strong>:</p>
<p>A <strong>time slice</strong>, also known as a time quantum, is a <strong>short interval of CPU time</strong> that is allocated to each process in Round Robin scheduling. The operating system scheduler assigns a time slice to a process, and the process is allowed to run for that duration. After the time slice expires, the process is preempted, and the CPU is given to the next process in the ready queue. Time slices ensure fair CPU sharing and responsiveness in time-sharing systems.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (a) (ii) (2 marks)</h3>
<div class="question-content">
<p>(ii) thread.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(ii) Thread</strong>:</p>
<p>A <strong>thread</strong> is a <strong>lightweight unit of execution within a process</strong>. It is a single sequential flow of control within a program. Multiple threads can exist within a single process and share the same process resources such as memory space, code segment, and data segment. Threads allow for concurrency within a process, enabling parallel execution of different parts of a program. Threads are often used to improve performance and responsiveness, especially in applications that can benefit from parallelism.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (b) (i) (2 marks)</h3>
<div class="question-content">
<p>(b) James was required to design an operating system that would perform a number of essentially independent tasks that do not need to be serialized.</p>
<p>(i) Identify the most appropriate processing technique that he could use justifying your answer.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Multiprocessing (Parallel Processing)</strong>:</p>
<p>The most appropriate processing technique for James is <strong>multiprocessing</strong>, also known as <strong>parallel processing</strong>. Multiprocessing involves using <strong>multiple CPUs or cores to execute multiple independent tasks simultaneously</strong>. Since the tasks are essentially independent and do not need to be serialized, multiprocessing can significantly improve performance by running these tasks in parallel, fully utilizing the available processing resources. This approach is ideal for tasks that can be divided and executed concurrently without dependencies.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (b) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Outline four advantages of the processing techniques identified in (i).</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Increased Throughput</strong>: <strong>Multiprocessing</strong> significantly <strong>increases system throughput</strong>. By executing multiple tasks in parallel across multiple processors, the system can accomplish more work in a given time. This is especially beneficial for tasks that can be divided into independent subtasks and processed concurrently, leading to higher overall processing capacity.</p>
<p data-number="2"><strong>Improved Performance for Concurrent Tasks</strong>: Multiprocessing provides <strong>improved performance for concurrent tasks</strong>. Applications that involve multiple independent operations or threads can run much faster when executed on a multiprocessing system. Tasks can be distributed among processors, allowing for true parallel execution and reduced execution times for concurrent workloads.</p>
<p data-number="3"><strong>Enhanced Responsiveness</strong>: Multiprocessing can enhance system <strong>responsiveness</strong>, especially in multi-user or multitasking environments. By distributing workload across multiple processors, the system can handle more user requests or application tasks concurrently without significant performance degradation. This leads to a more responsive and smoother user experience, even under heavy load.</p>
<p data-number="4"><strong>Fault Tolerance and Redundancy</strong>: In multiprocessing systems, the presence of <strong>multiple processors provides a degree of fault tolerance and redundancy</strong>. If one processor fails, the system can continue to operate, although possibly at a reduced performance level, using the remaining processors. This redundancy increases system reliability and availability, as the system is less likely to experience complete downtime due to a single processor failure.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (c) (i) (2 marks)</h3>
<div class="question-content">
<p>(c) (i) Explain the term process spawning as used in operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Process Spawning</strong>:</p>
<p><strong>Process spawning</strong>, also known as process creation, is the <strong>mechanism by which an existing process (parent process) creates one or more new processes (child processes)</strong>. It is the action of initiating a new process by the operating system, typically in response to a request from a running process or system event. Process spawning is fundamental for multitasking and allowing applications to perform concurrent operations by creating new processes as needed.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (c) (4 marks)</h3>
<div class="question-content">
<p>(i) Differentiate between cluster and sector as applied to physical storage disks.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Cluster</strong>:</p>
<p>A <strong>cluster</strong> is a <strong>group of sectors</strong> and is the <strong>smallest unit of disk space that is allocated to store a file</strong> by the operating system's file system. When a file is written to disk, space is allocated in units of clusters, not sectors. Even if a file is smaller than a cluster, a whole cluster is allocated to it. Cluster size is typically larger than sector size (e.g., 4KB, 8KB, etc.) and is determined during disk formatting. Using clusters reduces the overhead of managing disk space and file allocation metadata but can lead to internal fragmentation.</p>
<p><strong>Sector</strong>:</p>
<p>A <strong>sector</strong> is the <strong>smallest physical storage unit on a disk</strong>. It is a <strong>fixed-size block of data</strong>, traditionally 512 bytes or 4KB, that can be read or written in a single operation by the disk controller. Sectors are the fundamental building blocks of disk storage organization. Clusters are logical groupings of sectors managed by the file system, while sectors are hardware-level units managed by the disk controller.</p>
<p><strong>Key Difference:</strong> A sector is the smallest physical unit on a disk, while a cluster is a logical unit consisting of one or more sectors, and it is the smallest unit of disk space allocated to a file by the file system.</p>
</div>
</div>
</section>
<section class="question">
<h3>2. (d) (4 marks)</h3>
<div class="question-content">
<p>(d) Joy intends to buy an I/O device for her computer. Outline four factors that she should consider, other than the cost.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Performance (Speed and Throughput)</strong>: <strong>Performance</strong> is a crucial factor. Joy should consider the <strong>speed and throughput</strong> of the I/O device. For storage devices (like SSDs or HDDs), this includes data transfer rates (read/write speeds), access times, and latency. For network devices, it's data transmission speed. Higher performance devices improve system responsiveness and reduce I/O bottlenecks.</p>
<p data-number="2"><strong>Compatibility</strong>: <strong>Compatibility</strong> with her computer system is essential. Joy needs to ensure that the I/O device is <strong>compatible with her computer's interfaces</strong> (e.g., USB, PCIe, SATA), operating system, and drivers. Incompatibility can lead to non-functionality or performance issues. Checking compatibility specifications and driver availability is crucial before purchase.</p>
<p data-number="3"><strong>Reliability and Durability</strong>: <strong>Reliability and durability</strong> of the I/O device are important for long-term use and data integrity. For storage devices, this includes factors like MTBF (Mean Time Between Failures), endurance (for SSDs), and build quality. For other devices, robustness and lifespan are important. Choosing reliable and durable devices reduces the risk of failures and data loss.</p>
<p data-number="4"><strong>Power Consumption and Efficiency</strong>: <strong>Power consumption and efficiency</strong> should be considered, especially for portable computers or systems with power constraints. Power-efficient I/O devices can reduce energy usage, extend battery life in laptops, and lower overall system power requirements. Devices with lower power consumption are also often associated with less heat generation and improved thermal management.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (a) (i) (3 marks)</h3>
<div class="question-content">
<p>3. (a) (1) Outline three disadvantages of system buffering in I/O communications.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Increased Overhead</strong>: <strong>System buffering</strong> introduces <strong>overhead</strong>. Copying data to and from buffers requires CPU and memory bandwidth, adding to the overall processing time of I/O operations. For each data transfer, there are buffer management operations (allocation, deallocation, copying), which can consume system resources and reduce efficiency, especially for frequent small I/O transfers.</p>
<p data-number="2"><strong>Latency and Delay</strong>: Buffering can introduce <strong>latency and delay</strong> in data transfer. Data may need to be accumulated in the buffer before being processed or transferred further. This buffering delay can be noticeable in real-time or interactive applications where immediate data processing or response is required. Buffering can increase the overall response time of I/O operations.</p>
<p data-number="3"><strong>Complexity in Management</strong>: <strong>Buffer management</strong> adds <strong>complexity</strong> to the operating system and device drivers. The system needs to manage buffer allocation, deallocation, buffer sizes, and synchronization between buffer operations and process execution. Incorrect buffer management can lead to buffer overflows, data corruption, or synchronization issues, increasing the complexity of OS and driver development and maintenance.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (a) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Mitchell was required to investigate characteristics of a First-In, First-Out (FIFO) disk scheduling algorithm system. Describe two typical characteristics that she could have established.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Simplicity and Fairness</strong>: <strong>FIFO (First-In, First-Out) disk scheduling</strong>, also known as FCFS (First-Come, First-Served), is characterized by its <strong>simplicity and inherent fairness</strong>. It services disk I/O requests in the order they arrive in the queue, without prioritizing or reordering. This straightforward approach ensures that all requests are eventually served in the order of their arrival, providing a basic level of fairness among requests. Implementation is simple as it just requires maintaining a request queue.</p>
<p data-number="2"><strong>Poor Performance (High Seek Times)</strong>: A typical characteristic of FIFO disk scheduling is its <strong>potentially poor performance in terms of seek time and throughput</strong>. Because FIFO services requests in arrival order, it does not optimize disk head movement. This can lead to large disk head movements across the disk surface as requests may be for tracks far apart from each other. Consequently, FIFO can result in higher average seek times, increased rotational latency, and lower overall disk throughput compared to more optimized disk scheduling algorithms.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (b) (5 marks)</h3>
<div class="question-content">
<p>(b) A lecturer explained the desirable qualities of file organization to a class. Outline five qualities that he could be possibly facing.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Efficiency</strong>: <strong>Efficiency</strong> in file organization is crucial for minimizing disk access time and maximizing throughput. A good file organization method should allow for <strong>fast retrieval and storage of data</strong>, reducing I/O overhead. Efficiency can be measured in terms of access speed, storage space utilization, and the overhead of file operations.</p>
<p data-number="2"><strong>Ease of Access</strong>: <strong>Ease of access</strong> refers to how simple and convenient it is for users and applications to locate and access files. A desirable file organization should provide <strong>intuitive and logical access paths</strong> to files, making file retrieval straightforward. This includes well-structured directory hierarchies, clear naming conventions, and efficient search mechanisms.</p>
<p data-number="3"><strong>Data Integrity and Reliability</strong>: <strong>Data integrity and reliability</strong> are essential qualities. File organization should ensure that data is <strong>stored securely and reliably</strong>, protecting against data corruption, loss, and unauthorized access. Mechanisms for error detection, data redundancy, and backup/recovery contribute to data integrity and reliability.</p>
<p data-number="4"><strong>Adaptability and Scalability</strong>: A good file organization method should be <strong>adaptable to changing requirements and scalable to handle growing data volumes</strong>. It should be flexible enough to accommodate different file types, sizes, and access patterns, and should scale efficiently as the number of files and data size increases. Scalability ensures that the file system can handle future data growth without performance degradation.</p>
<p data-number="5"><strong>Security</strong>: <strong>Security</strong> is a critical quality. File organization should provide <strong>mechanisms to control access to files and directories</strong>, protecting sensitive data from unauthorized access, modification, or deletion. Security features like access permissions, encryption, and access control lists are essential for maintaining data confidentiality and integrity in a multi-user environment.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (c) (4 marks)</h3>
<div class="question-content">
<p>(c) Reader Company Ltd. is experiencing data security threats. Outline four threats that the company could be facing.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Malware Infections (Viruses, Worms, Trojans)</strong>: <strong>Malware infections</strong>, including viruses, worms, and Trojans, pose a significant threat. Malware can infiltrate systems, corrupt or delete data, disrupt operations, steal sensitive information, and spread to other systems. Malware threats can lead to data breaches, system instability, and financial losses.</p>
<p data-number="2"><strong>Data Breaches and Unauthorized Access</strong>: <strong>Data breaches</strong> involve unauthorized access to sensitive or confidential data by external attackers or insider threats. This can result in the <strong>leakage of proprietary information, customer data, financial records, or trade secrets</strong>. Data breaches can lead to financial losses, reputational damage, legal liabilities, and loss of customer trust.</p>
<p data-number="3"><strong>Phishing and Social Engineering Attacks</strong>: <strong>Phishing and social engineering attacks</strong> exploit human vulnerabilities to gain unauthorized access or information. Attackers may use deceptive emails, websites, or social tactics to trick employees into revealing credentials, sensitive data, or performing actions that compromise security. These attacks can lead to data breaches, malware infections, and financial fraud.</p>
<p data-number="4"><strong>Denial of Service (DoS) and Distributed Denial of Service (DDoS) Attacks</strong>: <strong>Denial of Service (DoS) and Distributed Denial of Service (DDoS) attacks</strong> aim to disrupt the availability of services by overwhelming systems with malicious traffic. DoS/DDoS attacks can make websites, applications, or network resources unavailable to legitimate users, causing business disruption, financial losses, and reputational damage.</p>
</div>
</div>
</section>
<section class="question">
<h3>3. (d) (4 marks)</h3>
<div class="question-content">
<p>(d) Pato installed a micro kernel operating system in his computer. Explain two benefit that he could realize while using it.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Improved System Stability and Reliability</strong>: <strong>Microkernel operating systems</strong> generally offer <strong>improved system stability and reliability</strong>. In a microkernel architecture, only essential core services run in kernel space, while other services (like file systems, device drivers, network stack) run in user space as servers. This separation reduces the risk of system-wide failures because a fault in a user-space service is less likely to crash the entire system. Fault isolation enhances robustness and reliability.</p>
<p data-number="2"><strong>Enhanced Security</strong>: Microkernels can provide <strong>enhanced security</strong>. By minimizing the amount of code running in privileged kernel mode, the attack surface of the system is reduced. Security vulnerabilities in user-space servers are less critical than vulnerabilities in a monolithic kernel because they have limited access to system-level resources. The principle of least privilege is better enforced in microkernels, improving overall system security and reducing the potential impact of security breaches.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (a) (3 marks)</h3>
<div class="question-content">
<p>(a) Outline three typical address information in a file directory.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>File Name</strong>: The <strong>file name</strong> is a human-readable name assigned to the file for identification and access. It is the primary way users and applications refer to a file within a directory. The file name is stored in the directory entry and is used to locate the file's metadata and data blocks.</p>
<p data-number="2"><strong>Starting Address (or Pointer)</strong>: The <strong>starting address</strong> or pointer in a directory entry indicates the <strong>location of the file's data on the storage device</strong>. This could be the starting block number, inode number, or the address of the first cluster where the file's data begins. The starting address is crucial for the file system to locate and retrieve the file's contents.</p>
<p data-number="3"><strong>File Attributes</strong>: Directory entries typically store <strong>file attributes</strong>, which describe various properties of the file. Attributes can include file type (e.g., regular file, directory), file size, timestamps (creation, modification, access times), access permissions, and ownership information. File attributes provide metadata about the file and control its behavior and access.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (b) (i) (2 marks)</h3>
<div class="question-content">
<p>(b) (i) Define the term key field as used in file management.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Key Field</strong>:</p>
<p>A <strong>key field</strong>, in file management and databases, is a <strong>specific field within a record or file that is used to uniquely identify each record</strong>. It serves as an index or identifier for records, allowing for efficient searching, sorting, and retrieval of records based on the value of this field. Key fields are essential for organizing and accessing data in structured files and databases.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (b) (ii) (5 marks)</h3>
<div class="question-content">
<p>(ii) Typically, users are granted certain access rights to a file. Outline five examples of access rights that can be assigned to a user.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Read</strong>: <strong>Read access</strong> right allows a user to <strong>view or read the contents of a file</strong>. Users with read access can open and read the file but cannot modify or delete it. This is a basic right for accessing file information.</p>
<p data-number="2"><strong>Write</strong>: <strong>Write access</strong> right permits a user to <strong>modify or write data to a file</strong>. Users with write access can change the file's contents, add new data, or overwrite existing data. Write access typically includes read access as well.</p>
<p data-number="3"><strong>Execute</strong>: <strong>Execute access</strong> right allows a user to <strong>run or execute a file</strong>, primarily applicable to executable files and scripts. For executable files, this right is necessary to launch and run the program. For directories, execute access may be required to enter or search the directory.</p>
<p data-number="4"><strong>Delete</strong>: <strong>Delete access</strong> right grants a user permission to <strong>remove or delete a file</strong>. Users with delete access can permanently erase the file from the file system. This right is often restricted to file owners or administrators.</p>
<p data-number="5"><strong>Append</strong>: <strong>Append access</strong> right allows a user to <strong>add data to the end of a file</strong> without modifying existing content. Users with append access can extend the file by adding new data at the end but cannot change or delete the existing content. This is useful for log files or data accumulation.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (c) (i) (2 marks)</h3>
<div class="question-content">
<p>(c) (i) Outline two problems that could be experienced with fixed memory partitioning.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Internal Fragmentation</strong>: <strong>Internal fragmentation</strong> is a problem where <strong>allocated partitions may be larger than the memory required by a process</strong>. The unused space within the partition is wasted and cannot be allocated to other processes, leading to inefficient memory utilization.</p>
<p data-number="2"><strong>External Fragmentation</strong>: <strong>External fragmentation</strong> can occur when <strong>total free memory is sufficient but is scattered into small, non-contiguous partitions</strong>. If a process requires a large contiguous block of memory, it may not be allocatable even if the total free memory is adequate, due to fragmentation.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (c) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Differentiate between block-oriented and Stream-oriented devices.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Block-Oriented Devices</strong>:</p>
<p><strong>Block-oriented devices</strong> transfer data in <strong>fixed-size blocks or chunks</strong>. Data is accessed and transferred in blocks, and each block has a specific address. These devices typically support random access to data blocks. Examples include <strong>hard disk drives (HDDs)</strong>, solid-state drives (SSDs), and USB drives. File systems are usually designed to work with block-oriented devices, managing storage in blocks (clusters) and providing file abstractions on top of block storage.</p>
<p><strong>Stream-Oriented Devices</strong>:</p>
<p><strong>Stream-oriented devices</strong> transfer data as a <strong>continuous stream of bytes or characters</strong>, without fixed block sizes. Data is accessed sequentially in a stream, and random access is generally not supported or efficient. Examples include <strong>keyboards</strong>, <strong>printers</strong>, and <strong>network interfaces</strong>. Data flows in a continuous stream, and operations typically involve reading or writing a sequence of bytes rather than addressing specific blocks.</p>
<p><strong>Key Difference:</strong> Block-oriented devices handle data in fixed-size blocks and support random access, while stream-oriented devices handle data as continuous streams of bytes and are primarily sequential access oriented.</p>
</div>
</div>
</section>
<section class="question">
<h3>4. (d) (4 marks)</h3>
<div class="question-content">
<p>(d) Memory paging is a popular technology in operating systems. Explain two advantages of the technology that could be influencing the trend.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Eliminates External Fragmentation</strong>: <strong>Memory paging</strong> effectively <strong>eliminates external fragmentation</strong>. Since memory is allocated in fixed-size pages and frames, there are no issues with fragmented free space between variable-sized blocks. All free memory is managed in units of frames, and any free frame can be used to store any page of any process. This efficient management of memory space reduces wastage and improves overall memory utilization.</p>
<p data-number="2"><strong>Supports Virtual Memory Efficiently</strong>: <strong>Paging is essential for efficient implementation of virtual memory</strong>. It provides the foundation for address translation, page swapping, and demand paging. Virtual memory systems rely on paging to manage the mapping between virtual addresses and physical addresses, allowing processes to use memory beyond the physical RAM capacity. Paging enables efficient swapping of pages between RAM and disk, making virtual memory practical and effective.</p>
</div>
</div>
</section>
<section class="question">
<h3>5. (a) (4 marks)</h3>
<div class="question-content">
<p>(a) Outline four desirable features of a file system.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Efficiency and Performance</strong>: A desirable file system should be <strong>efficient and provide good performance</strong>. This includes fast file access times, high throughput for read and write operations, and minimal overhead for file management operations. Efficiency in storage utilization and I/O operations is crucial for overall system performance.</p>
<p data-number="2"><strong>Reliability and Data Integrity</strong>: <strong>Reliability and data integrity</strong> are paramount. A good file system must ensure that data is stored reliably and protected against corruption or loss. This includes features like error detection and correction, data redundancy, and mechanisms to ensure data consistency even in case of system failures or crashes.</p>
<p data-number="3"><strong>Security and Access Control</strong>: <strong>Security features and robust access control</strong> are essential. A desirable file system should provide mechanisms to control access to files and directories, protecting sensitive data from unauthorized access, modification, or deletion. Access control should be flexible and granular, allowing administrators to define permissions for users and groups.</p>
<p data-number="4"><strong>User-Friendliness and Convenience</strong>: A file system should be <strong>user-friendly and convenient to use</strong>. This includes providing an intuitive directory structure, easy file naming conventions, and user-friendly tools for file management operations (create, delete, rename, copy, etc.). User convenience enhances productivity and simplifies file organization and access.</p>
</div>
</div>
</section>
<section class="question">
<h3>5. (b) (4 marks)</h3>
<div class="question-content">
<p>(b) Differentiate between memory address register (MAR), and memory buffer register (MBR), as applied in operating systems.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Memory Address Register (MAR)</strong>:</p>
<p>The <strong>Memory Address Register (MAR)</strong> is a CPU register that <strong>holds the address of a memory location that the CPU wants to access</strong>. When the CPU needs to read from or write to memory, it first loads the desired memory address into the MAR. The MAR is directly connected to the address bus, and it provides the address to the memory system for data access. The MAR specifies *where* in memory the CPU intends to operate.</p>
<p><strong>Memory Buffer Register (MBR)</strong>:</p>
<p>The <strong>Memory Buffer Register (MBR)</strong>, also known as the Memory Data Register (MDR), is a CPU register that <strong>holds the data being transferred to or from the memory location</strong> specified by the MAR. When the CPU writes data to memory, it places the data into the MBR, which is then written to the memory location indicated by the MAR. When the CPU reads data from memory, the data fetched from the memory location is placed into the MBR for the CPU to use. The MBR holds *what* data is being transferred between the CPU and memory.</p>
<p><strong>Key Difference:</strong> MAR holds the memory address (location), while MBR holds the actual data being transferred to or from that memory address. MAR specifies the *where*, and MBR specifies the *what* of memory access.</p>
</div>
</div>
</section>
<section class="question">
<h3>5. (c) (i) (4 marks)</h3>
<div class="question-content">
<p>(c) (i) Outline four reasons that would render a process into suspension state.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Swapping Out</strong>: A process may be <strong>suspended and swapped out to secondary storage (disk)</strong> to free up main memory. This is done when memory is overcommitted, and the system needs to reduce the number of processes in RAM to improve performance or make space for higher-priority processes. Swapping out is a form of temporary suspension to manage memory resources.</p>
<p data-number="2"><strong>User Request or Intervention</strong>: A user may <strong>explicitly request to suspend a process</strong>, for example, using a command like 'stop' or 'pause'. This could be done for debugging, system administration, or to temporarily halt a process's execution. User-initiated suspension is often a manual control action.</p>
<p data-number="3"><strong>Parent Process Request</strong>: A <strong>parent process may suspend one of its child processes</strong>. This can be done for process control, coordination, or synchronization purposes. A parent process might suspend a child to examine its state, modify its resources, or synchronize its execution with other parts of the application.</p>
<p data-number="4"><strong>System Load Balancing</strong>: In heavily loaded systems, the operating system may <strong>suspend lower-priority processes to improve the performance of higher-priority or critical processes</strong>. Suspension can be used as a dynamic load-balancing technique to ensure that important tasks get sufficient resources and responsiveness, even under high system load conditions.</p>
</div>
</div>
</section>
<section class="question">
<h3>5. (c) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Figure 1 shows virtual memory addressing scheme in an operating system.</p>
<p><img src="Screenshot_2025-03-12_at_12-37-12_2016july.pdf.png" alt="" width="686" height="381" /></p>
<p>Explain the two memory addresses labelled I. and II.</p>
<p><img src="paperpaper-003.png" alt="Figure 1" /></p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p>Based on the context of virtual memory addressing and the labels in Figure 1:</p>
<p><strong>I. Logical Address (or Virtual Address)</strong>:</p>
<p>Memory address labeled <strong>I</strong> is the <strong>Logical Address</strong>, also known as a <strong>Virtual Address</strong>. This is the address <strong>generated by the CPU</strong> when a program is executed. Logical addresses are part of the process's virtual address space. They are independent of the physical memory addresses and are translated by the Memory Management Unit (MMU) into physical addresses before actual memory access. Processes operate using logical addresses, which provide abstraction and protection.</p>
<p><strong>II. Physical Address</strong>:</p>
<p>Memory address labeled <strong>II</strong> is the <strong>Physical Address</strong>. This is the <strong>actual address in physical RAM (main memory) where data is stored</strong>. Physical addresses are used by the memory controller to access specific locations in physical memory chips. The MMU performs the <strong>translation from logical addresses to physical addresses</strong> using page tables or segment tables. Physical addresses are what the hardware understands and uses to access memory locations.</p>
<p><strong>Relationship:</strong> The virtual memory addressing scheme involves translating logical addresses (I) generated by the CPU into physical addresses (II) that correspond to actual locations in main memory. This translation is managed by the Memory Management Unit (MMU), enabling virtual memory functionality.</p>
</div>
</div>
</section>
<section class="question">
<h3>5. (d) (4 marks)</h3>
<div class="question-content">
<p>(d) Oliver was required to prepare a presentation on I/O facilities in operating system. Describe two I/O facilities that she could have highlighted in her presentation.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Buffering</strong>: <strong>Buffering</strong> is a key I/O facility. It involves using <strong>temporary storage areas (buffers) in memory to hold data during I/O transfers</strong>. Buffering helps to cope with speed mismatches between fast CPUs and slower I/O devices, allows for data size adaptation, and supports copy semantics. Techniques like single buffering, double buffering, and circular buffering are used to improve I/O performance and efficiency. Buffering is essential for smooth and efficient data flow between system components.</p>
<p data-number="2"><strong>Spooling</strong>: <strong>Spooling (Simultaneous Peripheral Operations On-Line)</strong> is an I/O facility, especially for output devices like printers. It involves <strong>redirecting output data to a disk buffer (spool area) instead of directly to the output device</strong>. A spooler process then manages the actual output to the device in the background. Spooling allows processes to generate output data quickly without waiting for the slower output device, improves system throughput, and enables features like print queuing and job scheduling for output operations.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (a) (i) (2 marks)</h3>
<div class="question-content">
<p>6. (a) (i) Outline two requirements for virtual memory in computers.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Paging or Segmentation Hardware Support</strong>: <strong>Hardware support for paging or segmentation</strong> is essential. The CPU and Memory Management Unit (MMU) must support address translation mechanisms to map virtual addresses to physical addresses. This hardware support typically includes page tables or segment tables, translation lookaside buffers (TLBs), and control registers to manage virtual memory operations efficiently.</p>
<p data-number="2"><strong>Secondary Storage (Disk Space)</strong>: Sufficient <strong>secondary storage space (disk space)</strong> is required to act as the backing store for virtual memory. Virtual memory uses disk space to store pages that are not currently in RAM. The swap space or page file on disk needs to be large enough to accommodate the virtual memory needs of running processes. Fast disk I/O performance is also important for efficient swapping and overall virtual memory performance.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (a) (4 marks)</h3>
<div class="question-content">
<p>(ii) Differentiate between a parent process and a child process.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Parent Process</strong>:</p>
<p>A <strong>parent process</strong> is an <strong>existing process that creates a new process</strong>. It is the process that initiates the creation of a child process using system calls like `fork()`. The parent process continues to exist after creating the child, and it can control and manage the child process. Parent processes are responsible for initiating and supervising child processes. They can share resources with children and communicate with them.</p>
<p><strong>Child Process</strong>:</p>
<p>A <strong>child process</strong> is a <strong>new process created by a parent process</strong>. It is a duplicate or a new instance of a program spawned by a parent process. The child process inherits certain attributes from its parent, such as code, data, open files, and environment. However, it has its own process ID (PID), memory space, and execution context. Child processes execute concurrently and independently of the parent process, although they can communicate and synchronize with the parent if needed.</p>
<p><strong>Key Difference:</strong> The parent process is the process that creates another process, while the child process is the newly created process. The parent process exists before and typically continues after the child process is created, and it has a hierarchical relationship with the child.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (b) (i) (2 marks)</h3>
<div class="question-content">
<p>(b) (i) Define the term thrashing as used in memory management.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Thrashing</strong>:</p>
<p><strong>Thrashing</strong> in memory management is a <strong>performance problem that occurs in virtual memory systems</strong> when the system spends <strong>more time swapping pages (page faults) than executing processes</strong>. This happens when the degree of multiprogramming is too high, and processes do not have enough pages in memory to execute efficiently. Constant page swapping between RAM and disk leads to very low CPU utilization and system performance grinds to a halt.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (b) (ii) (4 marks)</h3>
<div class="question-content">
<p>(ii) Explain two types of virtual memory replacement policy/strategy.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Least Recently Used (LRU)</strong>: The <strong>Least Recently Used (LRU)</strong> page replacement policy replaces the page that has <strong>not been used for the longest period in the past</strong>. LRU is based on the principle of locality of reference, assuming that pages that have not been accessed recently are less likely to be accessed in the near future. LRU aims to keep frequently used pages in memory and replace pages that are least likely to be needed again soon. It generally performs well but requires overhead to track page usage history.</p>
<p data-number="2"><strong>First-In, First-Out (FIFO)</strong>: The <strong>First-In, First-Out (FIFO)</strong> page replacement policy replaces the page that has been in memory for the <strong>longest time</strong>, regardless of its usage frequency. FIFO is simple to implement, as it only requires tracking the order in which pages were loaded into memory. However, FIFO may not always be efficient because pages that have been in memory longest are not necessarily the least useful. It can lead to Belady's anomaly in some cases, where increasing the number of frames can increase page faults.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (c) (2 marks)</h3>
<div class="question-content">
<p>(c) Figure 1 shows a typical file allocation method.</p>
<p><img src="Screenshot_2025-03-12_at_12-38-18_2016july.pdf.png" alt="" width="946" height="451" /></p>
<p>Use it to answer the question that follows.</p>
<p><img src="paperpaper-003.png" alt="Figure 1" /></p>
<p>(1) Describe the file allocation method depicted in the diagram.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Linked Allocation</strong>:</p>
<p>The file allocation method depicted in Figure 1 is <strong>linked allocation</strong>. In linked allocation, each file is a <strong>linked list of disk blocks</strong>. Blocks can be scattered anywhere on the disk. Each block contains data and a pointer to the next block in the file. The directory entry for each file contains a pointer to the first block of the file. Following the pointers in each block allows access to subsequent blocks of the file, forming a chain.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (c) (ii) (2 marks)</h3>
<div class="question-content">
<p>(ii) Outline two advantages of the file allocation method described in (i).</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>No External Fragmentation</strong>: <strong>Linked allocation</strong> effectively <strong>eliminates external fragmentation</strong>. Since file blocks do not need to be contiguous, any free block on the disk can be used to extend a file. This prevents the problem of free memory being fragmented into small, unusable chunks, improving disk space utilization.</p>
<p data-number="2"><strong>Dynamic File Size</strong>: Linked allocation supports <strong>dynamic file size</strong>. Files can grow in size dynamically at runtime because blocks can be added to the file's linked list as needed, without requiring contiguous space. This flexibility allows files to expand as required without pre-allocating a fixed amount of space, making it efficient for files that vary in size.</p>
</div>
</div>
</section>
<section class="question">
<h3>6. (c) (iii) (4 marks)</h3>
<div class="question-content">
<p>(iii) Explain two strategies that could be adapted to conserve disk space when using file allocation method described in (i).</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Cluster Size Optimization</strong>: Optimize <strong>cluster size</strong> to minimize internal fragmentation. While linked allocation eliminates external fragmentation, <strong>internal fragmentation</strong> can still occur if the cluster size is too large. By choosing an <strong>appropriate cluster size</strong>, the average wasted space per file due to clusters being larger than file sizes can be reduced. Smaller cluster sizes generally reduce internal fragmentation but may increase metadata overhead and potentially slow down sequential access for very large files.</p>
<p data-number="2"><strong>File Compression</strong>: Implement <strong>file compression</strong> techniques. <strong>Compressing files</strong> reduces the amount of disk space they occupy. By compressing files before storing them using linked allocation, the overall disk space usage can be significantly reduced. Compression algorithms can reduce file sizes, saving storage space, and also potentially improving I/O transfer times for compressed data. Decompression is performed when files are accessed, adding some processing overhead but saving disk space.</p>
</div>
</div>
</section>
<section class="question">
<h3>7. (a) (1 mark)</h3>
<div class="question-content">
<p>7. (a) For each of the following tasks identify appropriate file operation that could be used:</p>
<p>(i) replacing filename;</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Rename</strong></p>
</div>
</div>
</section>
<section class="question">
<h3>7. (a) (1 mark)</h3>
<div class="question-content">
<p>(ii) display file content;</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(ii) Read</strong></p>
</div>
</div>
</section>
<section class="question">
<h3>7. (a) (1 mark)</h3>
<div class="question-content">
<p>(iii) formatting a disk that contains files;</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(iii) Format (This operation is typically discouraged on disks with files as it erases all data)</strong></p>
</div>
</div>
</section>
<section class="question">
<h3>7. (a) (1 mark)</h3>
<div class="question-content">
<p>(iv) stores a new file in disk.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(iv) Create</strong></p>
</div>
</div>
</section>
<section class="question">
<h3>7. (b) (4 marks)</h3>
<div class="question-content">
<p>(b) Lucky was investigating factors influences deadlocks in operating systems. Outline four factors that he could have established.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Mutual Exclusion</strong>: <strong>Mutual exclusion</strong> is a necessary condition for deadlock. It occurs when <strong>resources are non-sharable</strong>, meaning only one process can use a resource at a time. If resources were infinitely sharable, processes would not need to wait for exclusive access, preventing deadlocks.</p>
<p data-number="2"><strong>Hold and Wait</strong>: <strong>Hold and wait</strong> is a deadlock condition where a process is <strong>holding at least one resource and is waiting to acquire additional resources held by other processes</strong>. If processes did not hold resources while waiting for new ones, deadlocks would be less likely to occur.</p>
<p data-number="3"><strong>No Preemption</strong>: <strong>No preemption</strong> is a condition where <strong>resources cannot be forcibly taken away from a process holding them</strong>. If resources could be preempted from processes, the OS could break deadlock cycles by taking resources away from one process and giving them to another.</p>
<p data-number="4"><strong>Circular Wait</strong>: <strong>Circular wait</strong> is a deadlock condition where there is a <strong>circular chain of processes</strong>, each waiting for a resource held by the next process in the chain. For example, process A waits for a resource held by B, B waits for a resource held by C, and C waits for a resource held by A, forming a cycle. Circular wait is a direct consequence of hold and wait and no preemption conditions.</p>
</div>
</div>
</section>
<section class="question">
<h3>7. (c) (4 marks)</h3>
<div class="question-content">
<p>(c) Programmers encounter several challenges when using memory overlay in operating systems. Explain two challenges that they are likely to experience.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Complexity of Program Design and Segmentation</strong>: <strong>Designing programs for overlaying is complex and requires significant programmer effort</strong>. Programmers must manually divide the program into overlays, determine the overlay structure, and manage the loading and unloading of overlays. This segmentation and overlay management process is intricate and error-prone, adding substantial complexity to software development.</p>
<p data-number="2"><strong>Increased Development and Maintenance Overhead</strong>: Memory overlay techniques lead to <strong>increased development and maintenance overhead</strong>. Programmers have to deal with the complexities of overlay management throughout the software lifecycle. Changes to the program structure or functionality can necessitate re-designing the overlay scheme. Debugging overlay-based programs is also more challenging due to the manual memory management and overlay loading logic, increasing maintenance costs and effort.</p>
</div>
</div>
</section>
<section class="question">
<h3>7. (d) (i) (4 marks)</h3>
<div class="question-content">
<p>(d) (i) Nancy intends to develop an operating system that would supports several types of RAID configurations. Explain two types of RAID configurations she should consider.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>RAID 0 (Striping)</strong>: <strong>RAID 0</strong>, known as <strong>striping</strong>, distributes data evenly across two or more disks without redundancy. Data is divided into stripes, and each stripe is written across the disks in the array. RAID 0 aims to <strong>improve performance</strong> by allowing parallel read and write operations across multiple disks, increasing throughput and speed. However, RAID 0 provides <strong>no fault tolerance</strong>; if any disk in the array fails, all data in the RAID 0 array is lost. It is suitable for applications where performance is critical and data redundancy is not a primary concern.</p>
<p data-number="2"><strong>RAID 1 (Mirroring)</strong>: <strong>RAID 1</strong>, known as <strong>mirroring</strong>, duplicates data across two disks, providing <strong>data redundancy and fault tolerance</strong>. Every write operation is performed on both disks in the mirror set. If one disk fails, data is still available from the other disk without data loss or downtime. RAID 1 enhances <strong>reliability and data availability</strong>. Read performance can also improve as read requests can be serviced from either disk. However, RAID 1 effectively halves the usable storage capacity, as half of the disk space is used for redundancy. It is suitable for critical systems where data reliability and availability are paramount.</p>
</div>
</div>
</section>
<section class="question">
<h3>7. (d) (4 marks)</h3>
<div class="question-content">
<p>(ii) The CPU uses several types of interrupt to handle I/O communications in a computer. Outline four types of interrupts that could be used in a computer.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Hardware Interrupts (Device Interrupts)</strong>: <strong>Hardware interrupts</strong> are generated by I/O devices to <strong>signal the CPU about an event requiring attention</strong>. Examples include: * <strong>Disk Interrupts</strong>: Signals completion of a disk read or write operation. * <strong>Network Interrupts</strong>: Indicates arrival of a network packet. * <strong>Keyboard Interrupts</strong>: Generated when a key is pressed. * <strong>Timer Interrupts</strong>: Generated by a hardware timer at regular intervals for time-slicing and system clock maintenance.</p>
<p data-number="2"><strong>Software Interrupts (System Calls)</strong>: <strong>Software interrupts</strong>, also known as traps or system calls, are <strong>generated by software to request services from the operating system kernel</strong>. When a user program needs to perform a privileged operation (e.g., file I/O, memory allocation, process control), it issues a system call, which triggers a software interrupt. Examples include `read()`, `write()`, `open()`, `exit()`, etc.</p>
<p data-number="3"><strong>Exceptions (Processor Exceptions)</strong>: <strong>Exceptions</strong> are interrupts generated by the CPU itself when it encounters an <strong>error or exceptional condition during program execution</strong>. Examples include: * <strong>Page Faults</strong>: Occurs when a process tries to access a memory page not currently in RAM. * <strong>Segmentation Faults</strong>: Memory access violation. * <strong>Division by Zero</strong>: Arithmetic error. * <strong>Illegal Instruction</strong>: Attempt to execute an invalid or privileged instruction in user mode.</p>
<p data-number="4"><strong>Inter-Processor Interrupts (IPIs)</strong>: <strong>Inter-Processor Interrupts (IPIs)</strong> are used in <strong>multiprocessor systems</strong> to enable <strong>communication and synchronization between CPUs</strong>. One CPU can send an IPI to another CPU to request it to perform certain tasks, handle events, or synchronize operations. IPIs are essential for coordinating activities and managing shared resources in multiprocessor architectures.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (a) (i) (2 marks)</h3>
<div class="question-content">
<p>8. (a) (i) Explain the term frame as applied in memory management.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Frame</strong>:</p>
<p>In memory management, a <strong>frame</strong> is a <strong>fixed-size block of physical memory (RAM)</strong>. When using paging, physical memory is divided into equal-sized blocks called frames. Frames are the units into which physical memory is divided and are used to hold pages of processes. The size of a frame is the same as the size of a page (typically 4KB or 8KB).</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (a) (4 marks)</h3>
<div class="question-content">
<p>(ii) Differentiate between fetch and cleaning policies as applied in virtual memory.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>Fetch Policy</strong>:</p>
<p>A <strong>fetch policy</strong> in virtual memory management <strong>determines when a page should be brought into main memory (RAM)</strong>. It decides when to load a page from secondary storage (disk) into a frame in RAM. Common fetch policies include: * <strong>Demand Paging</strong>: Pages are loaded into memory <strong>only when they are needed</strong> (on demand), i.e., when a page fault occurs. * <strong>Prepaging</strong>: <strong>Multiple pages are loaded into memory in advance</strong>, anticipating future needs, often based on locality of reference or program behavior patterns.</p>
<p>Fetch policy is about *when* to bring a page into RAM.</p>
<p><strong>Cleaning Policy</strong>:</p>
<p>A <strong>cleaning policy</strong> in virtual memory management <strong>determines when a modified page (dirty page) in RAM should be written back to secondary storage (disk)</strong>. It decides when to write back a page from RAM to disk to update the copy on disk. Common cleaning policies include: * <strong>Demand Cleaning</strong>: Dirty pages are written back to disk <strong>only when they are selected for replacement</strong> (page replacement). * <strong>Precleaning</strong>: Dirty pages are written back to disk <strong>periodically or in batches</strong>, before they are needed to be replaced, often to maintain a pool of clean frames.</p>
<p>Cleaning policy is about *when* to write a modified page back to disk.</p>
<p><strong>Key Difference:</strong> Fetch policy concerns when to bring pages into RAM, while cleaning policy concerns when to write modified pages back to disk.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (b) (i) (2 marks)</h3>
<div class="question-content">
<p>(b) Clifford was required to design a general-purpose time-sharing system for his client.</p>
<p>(1) Describe the most appropriate process scheduling technique that he could use.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(i) Round Robin (RR) Scheduling</strong>:</p>
<p>The most appropriate process scheduling technique for a general-purpose time-sharing system is <strong>Round Robin (RR) scheduling</strong>. RR is designed to provide <strong>fairness and responsiveness in time-sharing environments</strong> by giving each process a small, equal time slice of CPU time in a cyclic manner. This approach ensures that no single process monopolizes the CPU, and all processes get a fair share of processing time, leading to good interactive performance.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (b) (ii) (2 marks)</h3>
<div class="question-content">
<p>(ii) Outline two disadvantages of process scheduling technique described in (i).</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Performance Overhead due to Context Switching</strong>: <strong>Round Robin scheduling</strong> can incur <strong>performance overhead due to frequent context switching</strong>. Since each process runs for only a short time slice before being preempted, the system performs context switches frequently, especially with small time quanta. Context switching involves saving and restoring process states, which consumes CPU time and can reduce overall system efficiency if the overhead becomes significant.</p>
<p data-number="2"><strong>Turnaround Time Variance</strong>: While Round Robin provides fairness in terms of CPU time allocation, it can lead to <strong>variance in turnaround time</strong>, especially for processes with similar burst times. Processes with longer burst times may experience longer overall turnaround times compared to Shortest Job Next (SJN) or similar algorithms. The uniform time slice allocation can result in longer completion times for processes that could have finished quicker with other scheduling approaches.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (b) (iii) (2 marks)</h3>
<div class="question-content">
<p>(iii) Explain one factor that affects performance in the process scheduling technique described in (i).</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p><strong>(iii) Time Quantum Size</strong>:</p>
<p>The <strong>size of the time quantum</strong> is a critical factor that affects the performance of <strong>Round Robin scheduling</strong>. * <strong>Small Time Quantum</strong>: A very small time quantum leads to <strong>frequent context switches</strong>, increasing overhead and potentially reducing CPU efficiency. While it improves responsiveness, excessive context switching can decrease throughput. * <strong>Large Time Quantum</strong>: A very large time quantum approaches <strong>First-Come, First-Served (FCFS) behavior</strong>. Responsiveness for interactive tasks may degrade, as long-running processes can monopolize the CPU for longer periods within a time slice. * <strong>Optimal Time Quantum</strong>: The <strong>optimal time quantum size</strong> is a balance and depends on system characteristics and workload. It should be large enough to allow for reasonable process execution before preemption, but small enough to maintain good responsiveness and fairness. Finding the right balance is crucial for RR performance.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (c) (4 marks)</h3>
<div class="question-content">
<p>(c) Memory segmentation allows programmers to create memory references in their design. Outline four advantages programmers could realize using memory references.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Modularity and Code Reusability</strong>: Memory segmentation <strong>enhances modularity in programming</strong>. Programmers can divide programs into logical segments (e.g., code, data, stack) and manage memory references within these segments. This modularity promotes code organization, making it easier to develop, debug, and maintain large programs. It also facilitates code reusability, as segments can be designed as independent modules that can be reused in different parts of the program or in other programs.</p>
<p data-number="2"><strong>Data and Code Protection</strong>: Memory segmentation provides <strong>memory protection</strong>. Segments can be assigned different access rights (read-only, read-write, execute), allowing the operating system to enforce protection boundaries between segments. This prevents accidental or malicious access to code or data segments, improving system security and program stability. Memory references within segments are controlled and validated, reducing the risk of memory corruption.</p>
<p data-number="3"><strong>Simplified Memory Management for Programmers</strong>: Segmentation can <strong>simplify memory management from the programmer's perspective</strong>. Programmers can think in terms of logical segments and memory references within those segments, rather than dealing with flat, linear memory addresses. The OS and hardware handle the mapping of segments to physical memory. This abstraction simplifies program development and reduces the burden of manual memory management for programmers.</p>
<p data-number="4"><strong>Efficient Data Sharing and Memory Sharing</strong>: Memory segmentation facilitates <strong>efficient data sharing and memory sharing between processes</strong>. Segments can be shared between processes, allowing them to access common code or data regions. Shared segments reduce memory duplication, save memory space, and enable efficient inter-process communication and data exchange. Programmers can use shared memory segments to implement shared libraries or shared data structures for concurrent applications.</p>
</div>
</div>
</section>
<section class="question">
<h3>8. (d) (4 marks)</h3>
<div class="question-content">
<p>(d) Distributed operating systems are widely used in many organizations. Explain two features that could be influencing the trend.</p>
</div>
<div class="answer-section">
<h4>Answer</h4>
<div class="answer-content">
<p data-number="1"><strong>Scalability and Performance</strong>: <strong>Scalability and performance</strong> are major factors driving the adoption of distributed operating systems. Distributed systems can easily scale to handle increasing workloads by adding more nodes (computers) to the system. Workload can be distributed across multiple machines, enabling parallel processing and higher throughput compared to single-system OS. This scalability allows organizations to accommodate growing demands and improve application performance by leveraging distributed computing resources.</p>
<p data-number="2"><strong>Fault Tolerance and High Availability</strong>: <strong>Fault tolerance and high availability</strong> are critical advantages of distributed operating systems. In a distributed system, if one node fails, the system can continue to operate using the remaining nodes. Redundancy and fault isolation in distributed architectures minimize the impact of hardware or software failures. This enhances system reliability and ensures high availability of services and applications, which is crucial for business-critical operations and continuous service delivery.</p>
</div>
</div>
</section>
</main></p>
<p></p>
<p></p>
<footer>THIS IS THE LAST PRINTED PAGE.</footer></div>
</div>
</div>
</article>
</section>
</div>
<div id='bottomPagination'>
<nav class="pagination noprt">
<a href="november_2016.html" class="prev"><span><span>&laquo; </span>Previous</span></a> <span class="sep">| </span><a href="november_2015.html" class="next"><span>Next<span> &raquo;</span></span></a>
</nav>
</div>
</div>
<script type="text/javascript" src="_intef_js.js"></script></body></html>